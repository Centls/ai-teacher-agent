"""
ç»Ÿä¸€æ—¥å¿—é…ç½®æ¨¡å—

æ—¥å¿—æ–‡ä»¶ç»“æ„ï¼š
- logs/server.log      # API è¯·æ±‚ã€å¯åŠ¨ä¿¡æ¯ã€é…ç½®åŠ è½½
- logs/knowledge.log   # çŸ¥è¯†åº“æ“ä½œï¼šä¸Šä¼ ã€åˆ é™¤ã€å‘é‡åŒ–
- logs/docling.log     # æ–‡æ¡£è§£æï¼šOCRã€æ ¼å¼è½¬æ¢ã€è€—æ—¶
- logs/rag.log         # RAG åº•å±‚ï¼šChromaDB æ“ä½œã€BM25 æ£€ç´¢
- logs/error.log       # æ‰€æœ‰é”™è¯¯æ±‡æ€»ï¼ˆè·¨æ¨¡å—ï¼‰

ç­–ç•¥ï¼š
- æŒ‰æ—¥æœŸè½®è½¬ï¼Œæ¯å¤©ä¸€ä¸ªæ–‡ä»¶
- ä¿ç•™ 7 å¤©å†å²
- å•æ–‡ä»¶æœ€å¤§ 50MB
- æ¯æ¬¡å¯åŠ¨å†™å…¥åˆ†éš”æ ‡è®°

ä¾èµ–ï¼šPython æ ‡å‡†åº“ loggingï¼ˆå®Œæ•´å¤ç”¨ï¼‰
"""

import logging
import sys
import os
from pathlib import Path
from datetime import datetime
from logging.handlers import TimedRotatingFileHandler
from typing import Optional

# æ—¥å¿—ç›®å½•
LOGS_DIR = Path(__file__).resolve().parent.parent.parent / "logs"
LOGS_DIR.mkdir(exist_ok=True)

# æ—¥å¿—æ ¼å¼
FILE_FORMAT = "%(asctime)s | %(levelname)-5s | %(name)s | %(message)s"
FILE_DATE_FORMAT = "%Y-%m-%d %H:%M:%S"
CONSOLE_FORMAT = "%(message)s"

# æ—¥å¿—çº§åˆ«æ˜ å°„
LOG_LEVELS = {
    "DEBUG": logging.DEBUG,
    "INFO": logging.INFO,
    "WARNING": logging.WARNING,
    "ERROR": logging.ERROR,
    "CRITICAL": logging.CRITICAL,
}


class MaxSizeTimedRotatingFileHandler(TimedRotatingFileHandler):
    """
    ç»“åˆæ—¶é—´è½®è½¬å’Œå¤§å°é™åˆ¶çš„æ—¥å¿—å¤„ç†å™¨

    - æ¯å¤© 0 ç‚¹è‡ªåŠ¨è½®è½¬
    - å•æ–‡ä»¶è¶…è¿‡ maxBytes ä¹Ÿä¼šè½®è½¬
    - ä¿ç•™ backupCount ä¸ªå†å²æ–‡ä»¶

    å¼ºä¾èµ–ï¼šlogging.handlers.TimedRotatingFileHandlerï¼ˆå®Œæ•´å¤ç”¨ï¼‰
    """

    def __init__(self, filename, when='midnight', interval=1,
                 backupCount=7, maxBytes=50*1024*1024, encoding='utf-8'):
        super().__init__(
            filename,
            when=when,
            interval=interval,
            backupCount=backupCount,
            encoding=encoding
        )
        self.maxBytes = maxBytes

    def shouldRollover(self, record):
        # å…ˆæ£€æŸ¥æ—¶é—´è½®è½¬
        if super().shouldRollover(record):
            return True
        # å†æ£€æŸ¥å¤§å°é™åˆ¶
        if self.maxBytes > 0:
            if self.stream is None:
                self.stream = self._open()
            try:
                self.stream.seek(0, 2)  # ç§»åˆ°æ–‡ä»¶æœ«å°¾
                if self.stream.tell() + len(self.format(record)) >= self.maxBytes:
                    return True
            except (OSError, ValueError):
                pass
        return False


class LoggerFactory:
    """
    æ—¥å¿—å·¥å‚ç±» - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ—¥å¿—å™¨

    ä½¿ç”¨æ–¹å¼ï¼š
        from src.core.logging_config import LoggerFactory
        logger = LoggerFactory.get_logger("knowledge")
        logger.info("æ–‡æ¡£ä¸Šä¼ æˆåŠŸ", extra={"file": "test.pdf", "size": "1.2MB"})
    """

    _loggers: dict = {}
    _initialized: bool = False
    _console_handler: Optional[logging.Handler] = None
    _error_handler: Optional[logging.Handler] = None

    # æ—¥å¿—å™¨é…ç½®
    LOGGER_CONFIG = {
        "server": {
            "file": "server.log",
            "level": "INFO",
            "description": "API è¯·æ±‚ã€å¯åŠ¨ä¿¡æ¯ã€é…ç½®åŠ è½½"
        },
        "knowledge": {
            "file": "knowledge.log",
            "level": "INFO",
            "description": "çŸ¥è¯†åº“æ“ä½œï¼šä¸Šä¼ ã€åˆ é™¤ã€å‘é‡åŒ–"
        },
        "docling_client": {
            "file": "docling_client.log",
            "level": "INFO",
            "description": "è°ƒç”¨ Docling API çš„è¯·æ±‚/å“åº”/è€—æ—¶"
        },
        "rag": {
            "file": "rag.log",
            "level": "INFO",
            "description": "RAG åº•å±‚ï¼šChromaDB æ“ä½œã€BM25 æ£€ç´¢"
        },
    }

    @classmethod
    def init(cls, console_level: str = "INFO", file_level: str = "DEBUG"):
        """
        åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ

        åº”åœ¨åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨ä¸€æ¬¡ï¼š
            LoggerFactory.init()
        """
        if cls._initialized:
            return

        # ========== æ•è·ç¬¬ä¸‰æ–¹åº“æ—¥å¿—ï¼ˆtransformers, chromadb ç­‰ï¼‰==========
        # è¿™äº›åº“çš„è­¦å‘Šé»˜è®¤è¾“å‡ºåˆ° stderrï¼Œéœ€è¦é‡å®šå‘åˆ° logging
        import warnings
        logging.captureWarnings(True)  # å°† warnings æ¨¡å—è¾“å‡ºé‡å®šå‘åˆ° logging

        # åˆ›å»º server.log çš„æ–‡ä»¶å¤„ç†å™¨ï¼ˆç”¨äºç¬¬ä¸‰æ–¹åº“æ—¥å¿—ï¼‰
        server_file = LOGS_DIR / "server.log"
        server_file_handler = MaxSizeTimedRotatingFileHandler(
            str(server_file),
            when='midnight',
            backupCount=7,
            maxBytes=50*1024*1024,
            encoding='utf-8'
        )
        server_file_handler.setLevel(logging.WARNING)  # åªè®°å½• WARNING åŠä»¥ä¸Š
        server_file_handler.setFormatter(
            logging.Formatter(FILE_FORMAT, datefmt=FILE_DATE_FORMAT)
        )

        # é…ç½®ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—å™¨ï¼Œä½¿å…¶è¾“å‡ºåˆ° server.log
        third_party_loggers = [
            "transformers",           # HuggingFace transformers
            "sentence_transformers",  # Sentence Transformers
            "chromadb",               # ChromaDB
            "httpx",                  # HTTP å®¢æˆ·ç«¯
            "httpcore",               # HTTP æ ¸å¿ƒ
            "py.warnings",            # Python warnings æ¨¡å—ï¼ˆé€šè¿‡ captureWarningsï¼‰
        ]
        for lib_name in third_party_loggers:
            lib_logger = logging.getLogger(lib_name)
            lib_logger.setLevel(logging.WARNING)  # åªè®°å½•è­¦å‘ŠåŠä»¥ä¸Š
            lib_logger.addHandler(server_file_handler)

        # åˆ›å»ºå…±äº«çš„æ§åˆ¶å°å¤„ç†å™¨ï¼ˆä½¿ç”¨ Rich å¦‚æœå¯ç”¨ï¼‰
        try:
            from rich.logging import RichHandler
            cls._console_handler = RichHandler(
                rich_tracebacks=True,
                markup=True,
                show_time=True,
                show_path=False,
                level=LOG_LEVELS.get(console_level, logging.INFO)
            )
        except ImportError:
            cls._console_handler = logging.StreamHandler(sys.stdout)
            cls._console_handler.setFormatter(logging.Formatter(CONSOLE_FORMAT))
            cls._console_handler.setLevel(LOG_LEVELS.get(console_level, logging.INFO))

        # åˆ›å»ºå…±äº«çš„é”™è¯¯æ—¥å¿—å¤„ç†å™¨ï¼ˆæ‰€æœ‰ ERROR çº§åˆ«æ—¥å¿—æ±‡æ€»ï¼‰
        error_file = LOGS_DIR / "error.log"
        cls._error_handler = MaxSizeTimedRotatingFileHandler(
            str(error_file),
            when='midnight',
            backupCount=7,
            maxBytes=50*1024*1024,
            encoding='utf-8'
        )
        cls._error_handler.setLevel(logging.ERROR)
        cls._error_handler.setFormatter(
            logging.Formatter(FILE_FORMAT, datefmt=FILE_DATE_FORMAT)
        )

        # é¢„åˆ›å»ºæ‰€æœ‰é…ç½®çš„æ—¥å¿—å™¨
        for name in cls.LOGGER_CONFIG:
            cls.get_logger(name)

        cls._initialized = True

        # å†™å…¥å¯åŠ¨æ ‡è®°
        cls._write_startup_marker()

    @classmethod
    def _write_startup_marker(cls):
        """åœ¨æ‰€æœ‰æ—¥å¿—æ–‡ä»¶ä¸­å†™å…¥å¯åŠ¨åˆ†éš”æ ‡è®°"""
        import platform

        marker = f"""
{'='*80}
ğŸš€ SERVER STARTED | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | PID: {os.getpid()}
   Python: {platform.python_version()} | Platform: {platform.system()} {platform.release()}
{'='*80}
"""
        # å†™å…¥åˆ°æ‰€æœ‰æ—¥å¿—æ–‡ä»¶
        for config in cls.LOGGER_CONFIG.values():
            log_file = LOGS_DIR / config["file"]
            try:
                with open(log_file, "a", encoding="utf-8") as f:
                    f.write(marker)
            except Exception:
                pass

        # ä¹Ÿå†™å…¥åˆ°é”™è¯¯æ—¥å¿—
        error_file = LOGS_DIR / "error.log"
        try:
            with open(error_file, "a", encoding="utf-8") as f:
                f.write(marker)
        except Exception:
            pass

    @classmethod
    def get_logger(cls, name: str) -> logging.Logger:
        """
        è·å–æŒ‡å®šåç§°çš„æ—¥å¿—å™¨

        Args:
            name: æ—¥å¿—å™¨åç§°ï¼Œå¯é€‰å€¼ï¼šserver, knowledge, docling, rag
                  æˆ–ä»»æ„è‡ªå®šä¹‰åç§°ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰

        Returns:
            logging.Logger: é…ç½®å¥½çš„æ—¥å¿—å™¨å®ä¾‹
        """
        if name in cls._loggers:
            return cls._loggers[name]

        # è·å–é…ç½®ï¼ˆå¦‚æœæ˜¯é¢„å®šä¹‰çš„ï¼‰
        config = cls.LOGGER_CONFIG.get(name, {
            "file": f"{name}.log",
            "level": "INFO",
            "description": f"Custom logger: {name}"
        })

        # åˆ›å»ºæ—¥å¿—å™¨
        logger = logging.getLogger(f"nexus.{name}")
        logger.setLevel(logging.DEBUG)  # æ—¥å¿—å™¨æœ¬èº«è®¾ä¸ºæœ€ä½çº§åˆ«ï¼Œç”± handler æ§åˆ¶
        logger.propagate = False  # é˜²æ­¢é‡å¤è¾“å‡º

        # æ¸…é™¤å·²æœ‰å¤„ç†å™¨ï¼ˆé˜²æ­¢é‡å¤æ·»åŠ ï¼‰
        logger.handlers.clear()

        # æ·»åŠ æ–‡ä»¶å¤„ç†å™¨
        log_file = LOGS_DIR / config["file"]
        file_handler = MaxSizeTimedRotatingFileHandler(
            str(log_file),
            when='midnight',
            backupCount=7,
            maxBytes=50*1024*1024,
            encoding='utf-8'
        )
        file_handler.setLevel(LOG_LEVELS.get(config["level"], logging.INFO))
        file_handler.setFormatter(
            logging.Formatter(FILE_FORMAT, datefmt=FILE_DATE_FORMAT)
        )
        logger.addHandler(file_handler)

        # æ·»åŠ æ§åˆ¶å°å¤„ç†å™¨ï¼ˆå…±äº«ï¼‰
        if cls._console_handler:
            logger.addHandler(cls._console_handler)

        # æ·»åŠ é”™è¯¯å¤„ç†å™¨ï¼ˆå…±äº«ï¼ŒERROR çº§åˆ«æ±‡æ€»åˆ° error.logï¼‰
        if cls._error_handler:
            logger.addHandler(cls._error_handler)

        cls._loggers[name] = logger
        return logger


# ä¾¿æ·å‡½æ•°ï¼šè·å–å„æ¨¡å—æ—¥å¿—å™¨
def get_server_logger() -> logging.Logger:
    """è·å– server æ—¥å¿—å™¨ - API è¯·æ±‚ã€å¯åŠ¨ä¿¡æ¯"""
    return LoggerFactory.get_logger("server")

def get_knowledge_logger() -> logging.Logger:
    """è·å– knowledge æ—¥å¿—å™¨ - çŸ¥è¯†åº“æ“ä½œ"""
    return LoggerFactory.get_logger("knowledge")

def get_docling_logger() -> logging.Logger:
    """è·å– docling_client æ—¥å¿—å™¨ - è°ƒç”¨ Docling API çš„è¯·æ±‚/å“åº”/è€—æ—¶"""
    return LoggerFactory.get_logger("docling_client")

def get_rag_logger() -> logging.Logger:
    """è·å– rag æ—¥å¿—å™¨ - RAG åº•å±‚æ“ä½œ"""
    return LoggerFactory.get_logger("rag")


# æ—¥å¿—è£…é¥°å™¨ï¼šè®°å½•å‡½æ•°æ‰§è¡Œæ—¶é—´
def log_execution_time(logger_name: str = "server"):
    """
    è£…é¥°å™¨ï¼šè®°å½•å‡½æ•°æ‰§è¡Œæ—¶é—´

    ä½¿ç”¨æ–¹å¼ï¼š
        @log_execution_time("knowledge")
        def upload_document(...):
            ...
    """
    import functools
    import time

    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            logger = LoggerFactory.get_logger(logger_name)
            start_time = time.time()
            func_name = func.__name__

            logger.debug(f"å¼€å§‹æ‰§è¡Œ: {func_name}")
            try:
                result = func(*args, **kwargs)
                duration = time.time() - start_time
                logger.info(f"æ‰§è¡Œå®Œæˆ: {func_name} | è€—æ—¶: {duration:.2f}s")
                return result
            except Exception as e:
                duration = time.time() - start_time
                logger.error(f"æ‰§è¡Œå¤±è´¥: {func_name} | è€—æ—¶: {duration:.2f}s | é”™è¯¯: {e}")
                raise

        @functools.wraps(func)
        async def async_wrapper(*args, **kwargs):
            logger = LoggerFactory.get_logger(logger_name)
            start_time = time.time()
            func_name = func.__name__

            logger.debug(f"å¼€å§‹æ‰§è¡Œ: {func_name}")
            try:
                result = await func(*args, **kwargs)
                duration = time.time() - start_time
                logger.info(f"æ‰§è¡Œå®Œæˆ: {func_name} | è€—æ—¶: {duration:.2f}s")
                return result
            except Exception as e:
                duration = time.time() - start_time
                logger.error(f"æ‰§è¡Œå¤±è´¥: {func_name} | è€—æ—¶: {duration:.2f}s | é”™è¯¯: {e}")
                raise

        import asyncio
        if asyncio.iscoroutinefunction(func):
            return async_wrapper
        return wrapper

    return decorator
"""
AI è¥é”€è€å¸ˆ - CRAG èŠ‚ç‚¹å®ç° (White-box Reuse)

å¤ç”¨æ¥æº: Agentic-RAG-Ollama/scripts/nodes.py
é€‚é…:
1. æ›¿æ¢ ChatOllama ä¸º DeepSeek (OpenAI Compatible)
2. æ›¿æ¢é‡‘è Prompt ä¸ºè¥é”€ Prompt
3. é›†æˆé¡¹ç›®å†…éƒ¨ RAGPipeline
"""

from typing import List, Annotated, Dict, Any, Optional, Literal
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage
from pydantic import BaseModel, Field
import operator
import os
from langgraph.types import interrupt
from openai import OpenAI
import instructor

from src.agents.marketing.llm import llm  # ä½¿ç”¨é¡¹ç›®ç»Ÿä¸€é…ç½®çš„ DeepSeek LLM
from src.services.rag.multimodal_pipeline import MultimodalRAGPipeline  # ç»Ÿä¸€ä½¿ç”¨å¤šæ¨¡æ€ Pipeline
from src.services.rag.query_rewriter import QueryRewriter  # Query Rewritingï¼ˆå†å²èåˆ + Multi-Queryï¼‰
from src.services.rag.query_understanding import analyze_query, create_chat_history_summary  # Query Understandingï¼ˆInstructorï¼‰
from src.agents.marketing.learning import reflect_on_feedback
from langgraph.store.base import BaseStore
from config.settings import settings


def keep_latest(current: Any, new: Any) -> Any:
    """
    Reducer that keeps the latest (newest) value, used for flag fields.
    Handles initial state where current might be None.
    """
    if new is not None:
        return new
    if current is not None:
        return current
    return False  # Default for bool fields

# =============================================================================
# Web Search Tools (White-box Reuse: langchain_community)
# å¤ç”¨æ¥æº: menonpg/agentic_search_openai_langgraph
# =============================================================================
from langchain_community.tools import DuckDuckGoSearchResults

# =============================================================================
# State å®šä¹‰
# =============================================================================

class MarketingState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]
    question: str
    retrieved_docs: str  # æœ€ç»ˆåˆå¹¶åçš„æ–‡æ¡£ï¼ˆç”¨äºç”Ÿæˆï¼‰
    kb_docs: str  # çŸ¥è¯†åº“æ£€ç´¢çš„æ–‡æ¡£
    web_docs: str  # Web æœç´¢çš„æ–‡æ¡£
    rewritten_queries: List[str]
    generation: str
    grade: str  # 'yes', 'partial', 'no' - æ·»åŠ  partial ç”¨äºè¡¥å……æ··åˆ
    hallucination_grade: str # 'yes' or 'no'
    answer_grade: str # 'yes' or 'no'
    retry_count: int
    user_feedback: Optional[str]
    source_type: Literal["knowledge_base", "web_search", "hybrid", "fallback"]  # æ·»åŠ  hybrid ç±»å‹
    force_web_search: Annotated[bool, keep_latest]  # ä½¿ç”¨ reducer ç¡®ä¿å€¼è¢«æ­£ç¡®ä¼ é€’
    skip_hitl: Annotated[bool, keep_latest]  # æ‹’ç»åè·³è¿‡äººå·¥å®¡æ‰¹

# =============================================================================
# Pydantic Schemas (å¤ç”¨è‡ª Agentic-RAG)
# =============================================================================

class GradeDocuments(BaseModel):
    """Relevance score for retrieved documents."""
    relevance_score: str = Field(
        description="Document relevance: 'yes' (highly relevant), 'partial' (somewhat relevant, may need supplement), 'no' (not relevant)"
    )

class GradeHallucinations(BaseModel):
    """Binary score for hallucination present in generation answer."""
    binary_score: str = Field(description="Answer is grounded with the facts for the query, 'yes' or 'no'")

class GradeAnswer(BaseModel):
    """Binary score to assess answer addresses query."""
    binary_score: str = Field(description="Answer addresses the query, 'yes' or 'no'")

class SearchQueries(BaseModel):
    """Search queries for retrieving missing information."""
    search_queries: list[str] = Field(description="1-3 search queries to retrieve the missing information.")


class KnowledgeTypeClassification(BaseModel):
    """
    çŸ¥è¯†ç±»å‹åˆ†ç±»ç»“æœ
    å¤ç”¨é¡¹ç›® LLM è¿›è¡Œæ„å›¾åˆ†ç±»ï¼Œå†³å®šæ£€ç´¢å“ªä¸ªçŸ¥è¯†å­åº“
    """
    knowledge_type: str = Field(
        description="Knowledge type: 'product_raw' (product features/specs), 'sales_raw' (sales skills/objection handling), 'material' (copywriting/marketing materials), 'conclusion' (best practices/conclusions), 'all' (search all types)"
    )
    reasoning: str = Field(description="Brief reasoning for this classification")


# =============================================================================
# çŸ¥è¯†ç±»å‹å®šä¹‰ (ä¸ server.py ä¿æŒä¸€è‡´)
# =============================================================================
KNOWLEDGE_TYPES = {
    "product_raw": "äº§å“åŸå§‹èµ„æ–™",
    "sales_raw": "é”€å”®ç»éªŒ/è¯æœ¯",
    "material": "æ–‡æ¡ˆ/ç´ æ",
    "conclusion": "ç»“è®ºå‹çŸ¥è¯†",
}

# =============================================================================
# Helper Functions
# =============================================================================

def get_latest_user_query(messages: List[BaseMessage]) -> str:
    for message in reversed(messages):
        if isinstance(message, HumanMessage):
            return message.content
    return messages[0].content if messages else ''


# ========== Schema å®šä¹‰ï¼ˆçŸ¥è¯†åˆ†ç±»ï¼‰==========
class KnowledgeClassification(BaseModel):
    """çŸ¥è¯†ç±»å‹åˆ†ç±»ç»“æœ"""
    knowledge_type: Literal["product_raw", "sales_raw", "material", "conclusion", "all"] = Field(
        description="çŸ¥è¯†ç±»å‹: product_raw(äº§å“èµ„æ–™), sales_raw(é”€å”®è¯æœ¯), material(æ–‡æ¡ˆç´ æ), conclusion(ç»“è®ºçŸ¥è¯†), all(ç»¼åˆ)"
    )


# çŸ¥è¯†åˆ†ç±»ç³»ç»Ÿæç¤ºè¯ï¼ˆé…ç½®å±‚ï¼‰
_CLASSIFY_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªè¥é”€çŸ¥è¯†åˆ†ç±»ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œåˆ¤æ–­åº”è¯¥æ£€ç´¢å“ªç§ç±»å‹çš„çŸ¥è¯†åº“ã€‚

çŸ¥è¯†åº“ç±»å‹ï¼š
- product_raw: äº§å“åŠŸèƒ½ã€è§„æ ¼ã€ç‰¹æ€§ã€æŠ€æœ¯å‚æ•°ç­‰äº§å“åŸå§‹èµ„æ–™
- sales_raw: é”€å”®æŠ€å·§ã€è¯æœ¯ã€å®¢æˆ·å¼‚è®®å¤„ç†ã€æˆäº¤ç­–ç•¥ç­‰é”€å”®ç»éªŒ
- material: å®£ä¼ æ–‡æ¡ˆã€è¥é”€ç´ æã€å¹¿å‘Šè¯­ã€æ¨å¹¿å†…å®¹ç­‰
- conclusion: æœ€ä½³å®è·µã€ç­–ç•¥æ€»ç»“ã€æ–¹æ³•è®ºã€ç»“è®ºæ€§çŸ¥è¯†
- all: é—®é¢˜æ¶‰åŠå¤šä¸ªç±»å‹ï¼Œéœ€è¦ç»¼åˆæ£€ç´¢

åˆ†ç±»åŸåˆ™ï¼š
1. é—®äº§å“æ˜¯ä»€ä¹ˆã€æœ‰ä»€ä¹ˆåŠŸèƒ½ â†’ product_raw
2. é—®æ€ä¹ˆå–ã€æ€ä¹ˆè¯´æœå®¢æˆ·ã€æ€ä¹ˆå¤„ç†å¼‚è®® â†’ sales_raw
3. éœ€è¦æ–‡æ¡ˆã€ç´ æã€å®£ä¼ å†…å®¹ â†’ material
4. é—®æœ€ä½³å®è·µã€ç­–ç•¥å»ºè®®ã€æ–¹æ³•è®º â†’ conclusion
5. é—®é¢˜æ¨¡ç³Šæˆ–æ¶‰åŠå¤šæ–¹é¢ â†’ all"""


def classify_knowledge_type(question: str) -> str:
    """
    ä½¿ç”¨ Instructor + LLM åˆ†ç±»ç”¨æˆ·é—®é¢˜æ‰€éœ€çš„çŸ¥è¯†ç±»å‹

    å¼ºä¾èµ–å¤ç”¨ï¼š
    - instructor: ç»“æ„åŒ–è¾“å‡ºï¼ˆå®Œæ•´å¤ç”¨ï¼Œä¸é‡å†™ï¼‰
    - langsmith: è¿½è¸ªï¼ˆé€šè¿‡ traced è£…é¥°å™¨å¤ç”¨ï¼‰

    Returns:
        str: çŸ¥è¯†ç±»å‹ ('product_raw', 'sales_raw', 'material', 'conclusion', 'all')
    """
    # ä½¿ç”¨ç»Ÿä¸€ Instructor Clientï¼ˆå¸¦ LangSmith è¿½è¸ªï¼‰
    from src.core.instructor_client import get_instructor_client, traced, get_model_name

    @traced(name="classify_knowledge_type", run_type="chain")
    def _classify(q: str) -> str:
        client = get_instructor_client()

        # ä¾èµ–ï¼šinstructor.chat.completions.createï¼ˆå®Œæ•´å¤ç”¨ï¼Œä¸é‡å†™ï¼‰
        result = client.chat.completions.create(
            model=get_model_name(),
            messages=[
                {"role": "system", "content": _CLASSIFY_SYSTEM_PROMPT},
                {"role": "user", "content": f"ç”¨æˆ·é—®é¢˜: {q}"}
            ],
            response_model=KnowledgeClassification,
            max_retries=2  # instructor å†…ç½®é‡è¯•æœºåˆ¶ï¼ˆå®Œæ•´å¤ç”¨ï¼‰
        )
        return result.knowledge_type

    try:
        result = _classify(question)
        print(f"[CLASSIFY/Instructor] Question: '{question[:50]}...' -> Type: {result}")
        return result

    except Exception as e:
        print(f"[CLASSIFY/Instructor] Error: {e}, fallback to 'all'")
        return "all"

def detect_web_search_intent(question: str) -> bool:
    """
    æ£€æµ‹ç”¨æˆ·æ˜¯å¦æ˜ç¡®è¯·æ±‚è¿›è¡Œ Web æœç´¢ï¼ˆè”ç½‘æœç´¢ï¼‰

    æ³¨æ„ï¼šä»…å½“ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºè¦è¿›è¡Œ"è”ç½‘"/"ç½‘ç»œ"æœç´¢æ—¶æ‰è¿”å› True
    æ™®é€šçš„"æœç´¢xxx"åº”è¯¥ä½¿ç”¨çŸ¥è¯†åº“æ£€ç´¢ï¼Œè€Œé Web æœç´¢
    """
    # æ˜ç¡®çš„è”ç½‘æœç´¢å…³é”®è¯ï¼ˆå¿…é¡»åŒ…å«"è”ç½‘"ã€"ç½‘ç»œ"ã€"äº’è”ç½‘"ç­‰è¯ï¼‰
    explicit_web_keywords = [
        "è”ç½‘æœç´¢", "ç½‘ç»œæœç´¢", "åœ¨çº¿æœç´¢", "æœç´¢ç½‘ä¸Š", "æœç´¢äº’è”ç½‘",
        "web search", "search online", "search the web", "internet search",
        "æŸ¥ä¸€ä¸‹ç½‘ä¸Š", "å»ç½‘ä¸Šæ‰¾", "ä¸Šç½‘æŸ¥", "ç™¾åº¦ä¸€ä¸‹", "è°·æ­Œä¸€ä¸‹",
        "å¸®æˆ‘è”ç½‘", "ç”¨ç½‘ç»œ", "ä»ç½‘ä¸Š"
    ]

    # æ—¶æ•ˆæ€§å…³é”®è¯ï¼ˆè¡¨ç¤ºéœ€è¦æœ€æ–°ä¿¡æ¯ï¼‰
    realtime_keywords = [
        "æœ€æ–°", "å®æ—¶", "å½“å‰", "ä»Šå¤©çš„æ–°é—»", "æœ€è¿‘çš„æ–°é—»",
        "latest news", "current news", "real-time", "today's"
    ]

    question_lower = question.lower()

    # æ£€æŸ¥æ˜ç¡®çš„è”ç½‘æœç´¢æ„å›¾
    if any(keyword in question_lower for keyword in explicit_web_keywords):
        return True

    # æ£€æŸ¥æ—¶æ•ˆæ€§æ„å›¾ï¼ˆä½†éœ€è¦æ›´ä¸¥æ ¼çš„åŒ¹é…ï¼‰
    if any(keyword in question_lower for keyword in realtime_keywords):
        return True

    return False

# =============================================================================
# Nodes å®ç° (Adapted)
# =============================================================================

def retrieve_node(state: MarketingState) -> Dict[str, Any]:
    """
    æ£€ç´¢èŠ‚ç‚¹: ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£
    æ”¯æŒ:
    1. å‰ç«¯å¼€å…³æ§åˆ¶çš„ Web æœç´¢ (force_web_search ç›´æ¥ä¼ å…¥)
    2. æ™ºèƒ½æ„å›¾æ£€æµ‹ (ä»…ä½œä¸ºåå¤‡)
    3. æŒ‰çŸ¥è¯†ç±»å‹åˆ†ç±»æ£€ç´¢ (knowledge_type filter)
    4. Query Understandingï¼ˆInstructor å®ç°ï¼Œæå–å®ä½“/æ„å›¾/æ”¹å†™æŸ¥è¯¢ï¼‰
    5. Query Rewritingï¼ˆå†å²èåˆ + Multi-Queryï¼‰

    å¼ºä¾èµ–å¤ç”¨ï¼š
    - instructor: Query Understanding ç»“æ„åŒ–è¾“å‡ºï¼ˆå®Œæ•´å¤ç”¨ï¼‰
    - langsmith: è¿½è¸ªï¼ˆå®Œæ•´å¤ç”¨ï¼‰
    - langchain.chains.create_history_aware_retrieverï¼ˆå†å²èåˆï¼‰
    - langchain.retrievers.multi_query.MultiQueryRetrieverï¼ˆå¤šæŸ¥è¯¢æ‰©å±•ï¼‰
    """
    print("[RETRIEVE] Fetching documents...")

    # è·å–é—®é¢˜
    question = state.get("question")
    if not question:
        question = get_latest_user_query(state.get("messages", []))

    # è·å–å¯¹è¯å†å²ï¼ˆç”¨äºå†å²èåˆï¼‰
    messages = state.get("messages", [])

    # ========== Query Understandingï¼ˆInstructor å®ç°ï¼‰==========
    # å¼ºä¾èµ–ï¼šinstructor + langsmithï¼ˆå®Œæ•´å¤ç”¨ï¼‰
    # åŠŸèƒ½ï¼šæå–å®ä½“ã€åˆ¤æ–­æ„å›¾ã€æ”¹å†™æŸ¥è¯¢
    query_entities = []
    query_intent = None
    try:
        # åˆ›å»ºå¯¹è¯å†å²æ‘˜è¦ï¼ˆç”¨äºè§£å†³æŒ‡ä»£é—®é¢˜ï¼‰
        history_summary = create_chat_history_summary(messages, max_turns=3)

        # è°ƒç”¨ Query Understandingï¼ˆå¸¦ LangSmith è¿½è¸ªï¼‰
        qu_result = analyze_query(question, history_summary)

        query_entities = qu_result.entities
        query_intent = qu_result.intent

        # å¦‚æœ Query Understanding æ”¹å†™äº†æŸ¥è¯¢ï¼Œä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢
        if qu_result.standalone_query and qu_result.standalone_query != question:
            print(f"[QU] Query rewritten: '{question[:30]}...' -> '{qu_result.standalone_query[:30]}...'")
            question = qu_result.standalone_query

        print(f"[QU] Entities: {query_entities}, Intent: {query_intent}, Confidence: {qu_result.confidence:.2f}")
    except Exception as e:
        print(f"[QU] Query Understanding failed: {e}, continuing with original query")

    # æ£€æŸ¥å‰ç«¯å¼€å…³æ˜¯å¦å·²å¯ç”¨ Web æœç´¢
    force_web_search = state.get("force_web_search", False)

    # å¦‚æœå‰ç«¯æœªå¼€å¯ï¼Œæ‰æ£€æµ‹æ„å›¾ï¼ˆä½œä¸ºåå¤‡ï¼‰
    if not force_web_search:
        force_web_search = detect_web_search_intent(question)

    # åˆ†ç±»é—®é¢˜ç±»å‹ï¼Œå†³å®šæ£€ç´¢å“ªä¸ªçŸ¥è¯†å­åº“
    knowledge_type = classify_knowledge_type(question)
    metadata_filter = None if knowledge_type == "all" else {"knowledge_type": knowledge_type}
    print(f"[RETRIEVE] Knowledge type: {knowledge_type}, filter: {metadata_filter}")

    if force_web_search:
        print(f"[RETRIEVE] Web search mode enabled for: '{question}'")

        # æ™ºèƒ½æ··åˆæ¨¡å¼ï¼šå…ˆå°è¯•ä»çŸ¥è¯†åº“æ£€ç´¢
        pipeline = MultimodalRAGPipeline()
        try:
            docs = pipeline.retrieve(question, k=3, metadata_filter=metadata_filter)

            if docs and any(d.page_content.strip() for d in docs):
                # çŸ¥è¯†åº“æœ‰ç›¸å…³å†…å®¹ â†’ è§¦å‘æ··åˆæ¨¡å¼
                print(f"[RETRIEVE] Found {len(docs)} KB docs, triggering hybrid mode")

                # æ ¼å¼åŒ–çŸ¥è¯†åº“æ–‡æ¡£
                doc_texts = []
                for i, d in enumerate(docs, 1):
                    source_name = d.metadata.get('original_filename', 'Unknown Source')
                    doc_texts.append(f"[Source {i}] (File: {source_name}):\n{d.page_content}")

                kb_content = "\n\n".join(doc_texts)
                kb_formatted = f"## Query: {question}\n\n### Retrieved Documents:\n{kb_content}"

                return {
                    'retrieved_docs': kb_formatted,
                    'kb_docs': kb_formatted,
                    'question': question,
                    'force_web_search': True,
                    'grade': 'partial'  # è§¦å‘æ··åˆæœç´¢
                }
            else:
                # çŸ¥è¯†åº“æ— ç›¸å…³å†…å®¹ â†’ çº¯ Web æœç´¢
                print("[RETRIEVE] No relevant KB docs, triggering pure web search")
                return {
                    'retrieved_docs': '',
                    'kb_docs': '',
                    'question': question,
                    'force_web_search': True,
                    'grade': 'no'  # è§¦å‘çº¯ Web æœç´¢
                }
        except Exception as e:
            print(f"[RETRIEVE] KB search error: {e}, fallback to pure web search")
            return {
                'retrieved_docs': '',
                'kb_docs': '',
                'question': question,
                'force_web_search': True,
                'grade': 'no'
            }

    rewritten_queries = state.get('rewritten_queries', [])
    queries_to_search = rewritten_queries if rewritten_queries else [question]

    # è¯¦ç»†æ—¥å¿—ï¼šæ˜¾ç¤ºå°†è¦ä½¿ç”¨çš„æŸ¥è¯¢
    print(f"[RETRIEVE] rewritten_queries from state: {rewritten_queries}")
    print(f"[RETRIEVE] queries_to_search: {queries_to_search}")

    # åˆå§‹åŒ–å¤šæ¨¡æ€ RAG Pipeline
    pipeline = MultimodalRAGPipeline()

    # ========== Query Rewritingï¼ˆå†å²èåˆ + Multi-Queryï¼‰==========
    # ä¾èµ–ï¼šQueryRewriterï¼ˆå†…éƒ¨å¤ç”¨ LangChain ç»„ä»¶ï¼‰
    # - æœ‰å¯¹è¯å†å² â†’ å†å²èåˆï¼ˆè§£å†³æŒ‡ä»£æ¶ˆæ­§ï¼‰
    # - æ— å¯¹è¯å†å² â†’ Multi-Queryï¼ˆæå‡é¦–è½®å¬å›ï¼‰
    #
    # å†å²æˆªæ–­é…ç½®ï¼ˆå¯¹é½ä¸šç•Œæ ‡å‡†ï¼‰ï¼š
    # - è½®æ•°é™åˆ¶ï¼šæœ€è¿‘ 3 è½®ï¼ˆ6 æ¡æ¶ˆæ¯ï¼š3 Human + 3 AIï¼‰
    # - Token é™åˆ¶ï¼šçº¦ 2000 Tokenï¼ˆ~1500 æ±‰å­—ï¼‰
    REWRITER_MAX_TURNS = 3
    REWRITER_MAX_TOKENS = 2000  # çº¦ 1500 æ±‰å­—

    all_history = [m for m in messages[:-1] if isinstance(m, BaseMessage)] if len(messages) > 1 else []
    # æˆªæ–­åˆ°æœ€è¿‘ N è½®ï¼ˆæ¯è½® = 1 Human + 1 AI = 2 æ¡æ¶ˆæ¯ï¼‰
    recent_history = all_history[-(REWRITER_MAX_TURNS * 2):] if len(all_history) > REWRITER_MAX_TURNS * 2 else all_history

    # Token é™åˆ¶ï¼šæˆªæ–­è¶…å‡ºé™åˆ¶çš„æ¶ˆæ¯å†…å®¹
    max_chars = int(REWRITER_MAX_TOKENS * 0.75)  # 1 Token â‰ˆ 0.75 æ±‰å­—
    total_chars = 0
    chat_history = []

    for msg in recent_history:
        content = getattr(msg, 'content', '')
        content_len = len(content) if content else 0

        if total_chars + content_len > max_chars:
            # è¶…å‡ºé™åˆ¶ï¼Œæˆªæ–­å½“å‰æ¶ˆæ¯æˆ–åœæ­¢æ·»åŠ 
            remaining = max_chars - total_chars
            if remaining > 50:  # è‡³å°‘ä¿ç•™ 50 å­—ç¬¦æ‰æœ‰æ„ä¹‰
                truncated_content = content[:remaining] + "..."
                # ä¿æŒæ¶ˆæ¯ç±»å‹
                if isinstance(msg, HumanMessage):
                    chat_history.append(HumanMessage(content=truncated_content))
                elif isinstance(msg, AIMessage):
                    chat_history.append(AIMessage(content=truncated_content))
            break

        chat_history.append(msg)
        total_chars += content_len

    # åˆ¤æ–­æ˜¯å¦å¯ç”¨ Query Rewritingï¼ˆé¦–æ¬¡æ£€ç´¢æ—¶å¯ç”¨ï¼Œé‡è¯•æ—¶ä½¿ç”¨ rewritten_queriesï¼‰
    use_query_rewriting = not rewritten_queries  # æ²¡æœ‰é‡å†™æŸ¥è¯¢æ—¶æ‰ä½¿ç”¨ Query Rewriting

    if use_query_rewriting:
        try:
            # åˆ›å»º QueryRewriterï¼ˆå¤ç”¨ LangChain ç»„ä»¶ï¼‰
            query_rewriter = QueryRewriter(
                base_retriever=pipeline.vectorstore.as_retriever(search_kwargs={"k": 3, "filter": metadata_filter}),
                llm=llm
            )

            # ä½¿ç”¨ Query Rewriting æ£€ç´¢
            print(f"[RETRIEVE] Using QueryRewriter (history: {len(chat_history)} messages)")
            docs = query_rewriter.retrieve(question, chat_history if chat_history else None)

            if docs:
                # æ ¼å¼åŒ–æ–‡æ¡£å†…å®¹
                doc_texts = []
                for i, d in enumerate(docs, 1):
                    source_name = d.metadata.get('original_filename', 'Unknown Source')
                    doc_texts.append(f"[Source {i}] (File: {source_name}):\n{d.page_content}")

                combined_result = f"## Query: {question}\n\n### Retrieved Documents:\n" + "\n\n".join(doc_texts)

                return {
                    'retrieved_docs': combined_result,
                    'kb_docs': combined_result,
                    'question': question,
                    'source_type': 'knowledge_base'
                }
        except Exception as e:
            print(f"[RETRIEVE] QueryRewriter failed: {e}, fallback to direct retrieval")
            # é™çº§åˆ°ç›´æ¥æ£€ç´¢

    # ========== é™çº§/é‡è¯•ï¼šç›´æ¥æ£€ç´¢æ¨¡å¼ ==========
    all_results = []
    for idx, search_query in enumerate(queries_to_search, 1):
        print(f"[RETRIEVE] Query {idx}: {search_query}")

        # Extract keywords for BM25 Re-ranking (Simple strategy: split by space, filter short words)
        # In a full implementation, we might use an LLM to extract keywords, but this is efficient.
        keywords = [w for w in search_query.split() if len(w) > 2]

        # ä½¿ç”¨ MultimodalRAGPipeline è¿›è¡Œæ£€ç´¢ (Hybrid Search with Re-ranking + Knowledge Type Filter)
        docs = pipeline.retrieve(search_query, k=3, keywords=keywords, metadata_filter=metadata_filter)

        # æ ¼å¼åŒ–æ–‡æ¡£å†…å®¹ with Source IDs for citation
        doc_texts = []
        for i, d in enumerate(docs, 1):
            source_name = d.metadata.get('original_filename', 'Unknown Source')
            doc_texts.append(f"[Source {i}] (File: {source_name}):\n{d.page_content}")

        doc_txt = "\n\n".join(doc_texts)
        text = f"## Query {idx}: {search_query}\n\n### Retrieved Documents:\n{doc_txt}"
        all_results.append(text)

    combined_result = "\n\n".join(all_results)

    return {
        'retrieved_docs': combined_result,
        'kb_docs': combined_result,  # åŒæ—¶å­˜å‚¨åˆ° kb_docs
        'question': question,
        'source_type': 'knowledge_base'
    }

def grade_documents_node(state: MarketingState) -> Dict[str, Any]:
    """
    æ–‡æ¡£è¯„ä¼°èŠ‚ç‚¹: åˆ¤æ–­æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦ä¸é—®é¢˜ç›¸å…³ (Marketing Context)
    æ”¯æŒä¸‰çº§è¯„åˆ†: yes (å®Œå…¨ç›¸å…³), partial (éƒ¨åˆ†ç›¸å…³ï¼Œéœ€è¦è¡¥å……), no (ä¸ç›¸å…³)
    """
    print("[GRADE] Evaluating document relevance")

    # æ£€æŸ¥æ˜¯å¦å·²ç»ç”± retrieve_node è®¾ç½®äº† grade (æ™ºèƒ½æ··åˆæ¨¡å¼)
    existing_grade = state.get("grade")
    if existing_grade == "partial":
        # retrieve_node å·²åˆ¤æ–­ä¸ºæ··åˆæ¨¡å¼ï¼Œç›´æ¥ä¿æŒ
        print("[GRADE] Using pre-set grade from retrieve_node: partial (hybrid mode)")
        return {'grade': 'partial'}

    # å¦‚æœç”¨æˆ·æ˜ç¡®è¯·æ±‚ Web æœç´¢ä¸” grade='no'ï¼Œä¿æŒ force_web_search æ ‡å¿—
    force_web_search = state.get("force_web_search", False)
    if force_web_search and existing_grade == "no":
        print("[GRADE] Skipping - User explicitly requested web search (pure mode)")
        return {'grade': 'no', 'force_web_search': True}

    question = state.get("question")
    documents = state.get('retrieved_docs', '')

    if not documents:
        return {'grade': 'no'}

    llm_structured = llm.with_structured_output(GradeDocuments)

    # æ›´æ–°åçš„ Prompt æ”¯æŒä¸‰çº§è¯„åˆ†
    # NOTE: é˜¿é‡Œäº‘ API è¦æ±‚ä½¿ç”¨ json_object response_format æ—¶ï¼Œæ¶ˆæ¯ä¸­å¿…é¡»åŒ…å« "json" å…³é”®è¯
    # NOTE: å¿…é¡»åœ¨ prompt ä¸­æ˜ç¡®æŒ‡å®š JSON å­—æ®µåï¼Œå¦åˆ™ LLM å¯èƒ½è¿”å›ä¸åŒ¹é…çš„å­—æ®µå
    system_prompt = """You are a senior marketing strategist assessing the relevance of retrieved documents to a user's marketing question.

GRADING SCALE:
- 'yes': Documents are HIGHLY relevant and contain sufficient information to fully answer the query
- 'partial': Documents are SOMEWHAT relevant but may need supplementation with additional information (e.g., missing recent data, incomplete coverage)
- 'no': Documents are NOT relevant to the query at all

GUIDELINES:
- If documents contain core marketing concepts directly related to the query â†’ 'yes'
- If documents are tangentially related or cover only part of the query â†’ 'partial'
- If documents are completely unrelated to marketing or the specific query â†’ 'no'

You MUST respond with a JSON object containing EXACTLY this field:
{"relevance_score": "<yes|partial|no>"}"""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"Retrieved Document: {documents}\n\nUser query: {question}")
    ]

    try:
        response = llm_structured.invoke(messages)
        grade = response.relevance_score.lower()
        # æ ‡å‡†åŒ–è¾“å‡º
        if grade not in ['yes', 'partial', 'no']:
            grade = 'yes' if 'yes' in grade else ('partial' if 'partial' in grade else 'no')
    except Exception as e:
        print(f"[GRADE] Error: {e}")
        grade = "yes"  # Fallback

    print(f"[GRADE] Relevance: {grade}")

    if grade == 'yes':
        return {'grade': 'yes'}
    elif grade == 'partial':
        # éƒ¨åˆ†ç›¸å…³ï¼šä¿ç•™çŸ¥è¯†åº“æ–‡æ¡£ï¼Œè§¦å‘è¡¥å……æœç´¢
        return {'grade': 'partial'}
    else:
        return {'grade': 'no', 'retrieved_docs': ''}  # Clear docs if irrelevant

def _format_docs_summary(documents: str, max_chars_per_doc: int = 100) -> str:
    """
    å°†æ£€ç´¢æ–‡æ¡£æ ¼å¼åŒ–ä¸ºæ‘˜è¦å½¢å¼ï¼šæ¯æ¡æ˜¾ç¤ºæ ‡é¢˜ + å‰ N å­—ç¬¦

    Args:
        documents: åŸå§‹æ£€ç´¢æ–‡æ¡£å­—ç¬¦ä¸²
        max_chars_per_doc: æ¯æ¡æ–‡æ¡£å†…å®¹çš„æœ€å¤§å­—ç¬¦æ•°

    Returns:
        æ ¼å¼åŒ–åçš„æ‘˜è¦å­—ç¬¦ä¸²
    """
    if not documents:
        return "æ— ç›¸å…³æ–‡æ¡£"

    # è§£ææ–‡æ¡£æ ¼å¼: [Source X] (File: xxx):\nå†…å®¹
    import re
    pattern = r'\[(?:Source|Web Source)\s*(\d+)\]\s*(?:\(File:\s*([^)]+)\)|([^\n]+))[:ï¼š]?\n?(.*?)(?=\[(?:Source|Web Source)\s*\d+\]|$)'
    matches = re.findall(pattern, documents, re.DOTALL)

    if not matches:
        # æ— æ³•è§£æï¼Œè¿”å›æˆªæ–­çš„åŸå§‹å†…å®¹
        return documents[:500] + "..." if len(documents) > 500 else documents

    summaries = []
    for match in matches:
        source_num = match[0]
        file_name = match[1] if match[1] else match[2]  # File name or title
        content = match[3].strip()

        # æˆªå–å†…å®¹æ‘˜è¦
        content_preview = content[:max_chars_per_doc]
        if len(content) > max_chars_per_doc:
            content_preview += "..."

        # æ ¼å¼åŒ–æ‘˜è¦
        if file_name:
            summaries.append(f"[{source_num}] ğŸ“„ {file_name.strip()}\n   {content_preview}")
        else:
            summaries.append(f"[{source_num}] {content_preview}")

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    total_docs = len(summaries)
    header = f"å…±æ£€ç´¢åˆ° {total_docs} æ¡æ–‡æ¡£ï¼š\n\n"

    return header + "\n\n".join(summaries)


def human_approval_node(state: MarketingState) -> Dict[str, Any]:
    """
    HITL Approval Node: Interrupts execution to request user approval.
    ä¼ é€’ä¸Šä¸‹æ–‡ä¿¡æ¯ç»™ç”¨æˆ·å®¡æ ¸ï¼ŒåŒ…æ‹¬æ•°æ®æ¥æºç±»å‹

    å¦‚æœ skip_hitl ä¸º Trueï¼ˆæ‹’ç»åé‡è¯•ï¼‰ï¼Œåˆ™è·³è¿‡ä¸­æ–­ç›´æ¥è¿”å›
    """
    # è·å–å½“å‰çŠ¶æ€çš„è°ƒè¯•ä¿¡æ¯
    skip_hitl = state.get("skip_hitl", False)
    retry_count = state.get("retry_count", 0)
    print(f"[HITL] Entering human_approval_node - skip_hitl={skip_hitl}, retry_count={retry_count}")

    # æ£€æŸ¥æ˜¯å¦è·³è¿‡äººå·¥å®¡æ‰¹ï¼ˆæ‹’ç»åé‡è¯•åœºæ™¯ï¼‰
    if skip_hitl:
        print(f"[HITL] Skipping approval (skip_hitl=True, retry_count={retry_count})")
        # é‡ç½® skip_hitl æ ‡å¿—ï¼Œå¹¶è‡ªåŠ¨æ‰¹å‡†
        return {"user_feedback": "approved", "skip_hitl": False}

    print("[HITL] Requesting human approval")

    question = state.get("question", "")
    documents = state.get("retrieved_docs", "")
    source_type = state.get("source_type", "unknown")

    # æ ¹æ®æ¥æºç±»å‹ç”Ÿæˆä¸åŒçš„å®¡æ ¸æ¶ˆæ¯
    source_labels = {
        "knowledge_base": "ğŸ“š çŸ¥è¯†åº“",
        "web_search": "ğŸŒ Web æœç´¢",
        "hybrid": "ğŸ“š+ğŸŒ æ··åˆæ¥æºï¼ˆçŸ¥è¯†åº“ + Web è¡¥å……ï¼‰",
        "fallback": "âš ï¸ å¤‡ç”¨"
    }
    source_label = source_labels.get(source_type, source_type)

    # ç”Ÿæˆæ–‡æ¡£æ‘˜è¦ï¼ˆæ¯æ¡æ˜¾ç¤ºæ ‡é¢˜ + å‰ 100 å­—ï¼‰
    docs_summary = _format_docs_summary(documents, max_chars_per_doc=100)

    # ä¼ é€’å®¡æ ¸ä¸Šä¸‹æ–‡ç»™å‰ç«¯
    review_context = {
        "question": question,
        "retrieved_docs": docs_summary,  # ä½¿ç”¨æ‘˜è¦æ ¼å¼
        "source_type": source_type,
        "source_label": source_label,
        "message": f"æ•°æ®æ¥æº: {source_label}\nè¯·å®¡æ ¸æ£€ç´¢åˆ°çš„å†…å®¹æ˜¯å¦ç›¸å…³ï¼Œç¡®è®¤åå°†åŸºäºè¿™äº›å†…å®¹ç”Ÿæˆå›ç­”ã€‚"
    }

    # Interrupt execution and wait for user input
    user_input = interrupt(review_context)

    print(f"[HITL] User input: {user_input}")

    return {"user_feedback": user_input}

async def learning_node(state: MarketingState, store: BaseStore) -> Dict[str, Any]:
    """
    å­¦ä¹ èŠ‚ç‚¹: åˆ†æç”¨æˆ·åé¦ˆå¹¶æ›´æ–°åå¥½è§„åˆ™
    """
    print("[LEARNING] Analyzing feedback...")
    
    feedback = state.get("user_feedback")
    messages = state.get("messages")
    
    if not feedback:
        return {}
        
    # Get current rules
    namespace = ("marketing_preferences",)
    key = "user_rules"
    
    # Note: store.aget returns an Item or None
    current_rules_item = await store.aget(namespace, key)
    current_rules = current_rules_item.value["rules"] if current_rules_item and "rules" in current_rules_item.value else "*no rules yet*"
    
    # Reflect
    new_rules = await reflect_on_feedback(messages, current_rules)
    
    # Update store
    await store.aput(namespace, key, {"rules": new_rules})
    
    print(f"[LEARNING] Updated Rules: {new_rules}")
    
    return {}

async def generate_node(state: MarketingState, store: BaseStore) -> Dict[str, Any]:
    """
    ç”ŸæˆèŠ‚ç‚¹: åŸºäºæ–‡æ¡£ç”Ÿæˆè¥é”€å»ºè®® (Marketing Context)
    æ”¯æŒ Fallback: æ— ç›¸å…³æ–‡æ¡£æ—¶ä½¿ç”¨é€šç”¨å›ç­”
    """
    print("[GENERATE] Creating Answer")

    question = state.get("question")
    documents = state.get('retrieved_docs', '')
    retry_count = state.get("retry_count", 0)

    # Get user rules
    namespace = ("marketing_preferences",)
    key = "user_rules"
    current_rules_item = await store.aget(namespace, key)
    user_rules = current_rules_item.value["rules"] if current_rules_item and "rules" in current_rules_item.value else "*no rules yet*"

    # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å…³æ–‡æ¡£
    has_documents = bool(documents and documents.strip())

    if has_documents:
        # æ­£å¸¸æ¨¡å¼: åŸºäºæ–‡æ¡£ç”Ÿæˆ
        system_prompt = """You are an expert AI Marketing Consultant providing actionable, strategic advice.

    USER PREFERENCES:
    {user_rules}

    OUTPUT FORMAT:
    Write a comprehensive, engaging answer (200-300 words) in MARKDOWN format:
    - Use ## headings for key strategies
    - Use **bold** for emphasis
    - Use bullet points for actionable steps
    - Include inline citations like [1], [2] where applicable

    GUIDELINES:
    - Base your advice ONLY on the provided documents, but synthesize them into a coherent strategy.
    - Focus on marketing metrics (ROI, conversion, engagement) rather than just financial data.
    - Be practical and solution-oriented.
    - Use professional marketing terminology.

    CITATIONS:
    At the end, list references in this format:
    **References:**
    1. Source: [Document Name/Snippet]"""

        system_prompt = system_prompt.format(user_rules=user_rules)
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"Retrieved Document: {documents}\n\nUser query: {question}")
        ]
    else:
        # Fallback æ¨¡å¼: æ²¡æœ‰ç›¸å…³æ–‡æ¡£ï¼Œä½¿ç”¨é€šç”¨å›ç­”
        print(f"[GENERATE] Fallback mode - No relevant documents (retry_count: {retry_count})")
        system_prompt = """You are an AI Marketing Consultant.

The user's question doesn't seem to have relevant documents in our marketing knowledge base.

INSTRUCTIONS:
- If it's a general question (like "who are you"), introduce yourself as an AI Marketing teacher/consultant.
- If it's a marketing question we don't have docs for, provide general marketing principles and suggest the user upload relevant materials.
- Be helpful and friendly.
- Keep the response concise (100-150 words).
- Use MARKDOWN format.

USER PREFERENCES:
{user_rules}"""

        system_prompt = system_prompt.format(user_rules=user_rules)
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"User query: {question}")
        ]

    response = await llm.ainvoke(messages)
    generation = response.content

    return {
        'generation': generation,
        'messages': [AIMessage(content=generation)]
    }

def transform_query_node(state: MarketingState) -> Dict[str, Any]:
    """
    æŸ¥è¯¢é‡å†™èŠ‚ç‚¹: å°†å¤æ‚é—®é¢˜æ‹†è§£ä¸ºå…·ä½“çš„è¥é”€æœç´¢æŸ¥è¯¢ (Marketing Context)
    """
    print("[TRANSFORM] Rewriting query")

    question = state.get("question")
    rewritten_queries = state.get('rewritten_queries', [])
    current_retry = state.get("retry_count", 0)
    retry_count = current_retry + 1  # å¢åŠ é‡è¯•è®¡æ•°

    print(f"[TRANSFORM] Original question: '{question}'")
    print(f"[TRANSFORM] Previous rewritten_queries: {rewritten_queries}")
    print(f"[TRANSFORM] Current retry_count in state: {current_retry}, new retry_count: {retry_count}")

    llm_structured = llm.with_structured_output(SearchQueries)

    # Adapted Prompt for Marketing
    # NOTE: é˜¿é‡Œäº‘ API è¦æ±‚ä½¿ç”¨ json_object response_format æ—¶ï¼Œæ¶ˆæ¯ä¸­å¿…é¡»åŒ…å« "json" å…³é”®è¯
    # NOTE: å¿…é¡»åœ¨ prompt ä¸­æ˜ç¡®æŒ‡å®š JSON å­—æ®µåï¼Œå¦åˆ™ LLM å¯èƒ½è¿”å›ä¸åŒ¹é…çš„å­—æ®µå
    system_prompt = """You are a marketing research assistant that decomposes complex marketing questions into focused search queries.

DECOMPOSITION STRATEGY:
Break down the original query into 1-3 specific, focused queries targeting:
- Specific marketing channels (e.g., "SEO trends 2024", "Social media benchmarks")
- Target audience segments
- Competitor strategies
- Specific metrics (e.g., "CAC benchmarks", "Retention rates")

GUIDELINES:
- Expand marketing acronyms (e.g., "PPC" -> "Pay-per-click")
- Add marketing context if missing
- Make each query self-contained and specific
- Keep queries concise

CRITICAL RULE - YOU MUST FOLLOW THIS:
If previous queries are provided below, you MUST generate COMPLETELY DIFFERENT queries.
Do NOT repeat any previous query, even with minor word changes.
Try alternative angles, different keywords, or focus on different aspects of the topic.

EXAMPLES:
- "How to improve ROI on Facebook Ads?" ->
["Facebook Ads ROI optimization strategies", "Facebook advertising benchmarks 2024"]

You MUST respond with a JSON object containing EXACTLY this field:
{"search_queries": ["query1", "query2", ...]}"""

    query_context = f"Original Query: {question}"
    if rewritten_queries:
        query_context += f"""

âš ï¸ IMPORTANT: The following queries have ALREADY been tried and returned unsatisfactory results.
You MUST generate COMPLETELY NEW and DIFFERENT queries. Do NOT repeat these:

Previous Failed Queries:
"""
        for idx, q in enumerate(rewritten_queries, 1):
            query_context += f"{idx}. {q}\n"

        query_context += f"""
Generate NEW queries that:
- Use different keywords and phrases
- Explore different aspects of the topic
- Try alternative search angles (e.g., case studies, best practices, step-by-step guides)
- Consider related but distinct topics

Retry attempt: {retry_count}"""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=query_context)
    ]

    response = llm_structured.invoke(messages)
    new_queries = response.search_queries

    print(f"[TRANSFORM] New Queries: {new_queries} (retry: {retry_count})")

    # ä»£ç å±‚é¢æ£€æµ‹é‡å¤æŸ¥è¯¢ï¼ˆå¤‡ç”¨æœºåˆ¶ï¼‰
    # å¦‚æœ LLM ç”Ÿæˆçš„æŸ¥è¯¢ä¸ä¹‹å‰å®Œå…¨ç›¸åŒï¼Œä½¿ç”¨å¤‡ç”¨ç­–ç•¥
    if rewritten_queries and new_queries:
        # è®¡ç®—é‡å¤ç‡
        overlap_count = sum(1 for q in new_queries if q in rewritten_queries)
        overlap_ratio = overlap_count / len(new_queries) if new_queries else 0

        if overlap_ratio > 0.5:  # è¶…è¿‡ 50% é‡å¤
            print(f"[TRANSFORM] WARNING: {overlap_ratio*100:.0f}% queries are duplicates, using fallback strategy")

            # åŠ¨æ€åç¼€ç­–ç•¥ï¼šæ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©ç›¸å…³åç¼€
            knowledge_type = classify_knowledge_type(question)
            print(f"[TRANSFORM] Detected knowledge type: {knowledge_type}")

            # æŒ‰çŸ¥è¯†ç±»å‹å®šä¹‰åç¼€ï¼ˆæ›´è´´åˆçŸ¥è¯†åº“å†…å®¹ï¼‰
            type_specific_suffixes = {
                "product_raw": [
                    "äº§å“åŠŸèƒ½è¯¦è§£",
                    "æŠ€æœ¯å‚æ•°è¯´æ˜",
                    "äº§å“ä¼˜åŠ¿å¯¹æ¯”",
                    "æ ¸å¿ƒå–ç‚¹åˆ†æ",
                    "ä½¿ç”¨åœºæ™¯ä»‹ç»",
                    "äº§å“åŸç†è§£æ"
                ],
                "sales_raw": [
                    "å®¢æˆ·å¼‚è®®å¤„ç†",
                    "æˆäº¤è¯æœ¯æŠ€å·§",
                    "é”€å”®æ²Ÿé€šæ–¹æ³•",
                    "å®¢æˆ·éœ€æ±‚æŒ–æ˜",
                    "ä¿ƒå•ç­–ç•¥",
                    "é”€å”®å®æˆ˜ç»éªŒ"
                ],
                "material": [
                    "æ–‡æ¡ˆæ¨¡æ¿å‚è€ƒ",
                    "è¥é”€ç´ æç¤ºä¾‹",
                    "æ¨å¹¿å†…å®¹åˆ›æ„",
                    "å®£ä¼ æ–‡æ¡ˆå†™æ³•",
                    "å¹¿å‘Šè¯­è®¾è®¡",
                    "å†…å®¹è¥é”€æ¡ˆä¾‹"
                ],
                "conclusion": [
                    "æœ€ä½³å®è·µæ€»ç»“",
                    "ç­–ç•¥æ–¹æ³•è®º",
                    "ç»éªŒæ•™è®­åˆ†æ",
                    "å…³é”®æˆåŠŸå› ç´ ",
                    "æ‰§è¡Œè¦ç‚¹å½’çº³",
                    "æ ¸å¿ƒç»“è®ºæç‚¼"
                ],
                "all": [
                    "ç»¼åˆè§£å†³æ–¹æ¡ˆ",
                    "å…¨é¢åˆ†ææŠ¥å‘Š",
                    "ç³»ç»Ÿæ€§æŒ‡å—",
                    "å®Œæ•´æ–¹æ³•è®º",
                    "æ•´ä½“ç­–ç•¥è§„åˆ’",
                    "å¤šç»´åº¦åˆ†æ"
                ]
            }

            # æ ¹æ®çŸ¥è¯†ç±»å‹é€‰æ‹©åç¼€ç­–ç•¥
            if knowledge_type == "all":
                # ç»¼åˆæ€§é—®é¢˜ï¼šç”Ÿæˆ 4 ä¸ªæŸ¥è¯¢ï¼Œè¦†ç›–å…¨éƒ¨çŸ¥è¯†ç±»å‹
                all_types = ["product_raw", "sales_raw", "material", "conclusion"]

                new_queries = []
                question_short = question[:35]  # ç»¼åˆæŸ¥è¯¢ç”¨æ›´çŸ­çš„å‰ç¼€ï¼ˆ4ä¸ªæŸ¥è¯¢ï¼‰
                for t in all_types:
                    # æ¯æ¬¡é‡è¯•ä½¿ç”¨ä¸åŒçš„åç¼€ç´¢å¼•
                    suffix_index = (retry_count - 1) % len(type_specific_suffixes[t])
                    suffix = type_specific_suffixes[t][suffix_index]
                    new_queries.append(f"{question_short} {suffix}")

                print(f"[TRANSFORM] Fallback queries (ç»¼åˆ, å…¨ç±»å‹è¦†ç›–, retry={retry_count}): {new_queries}")
            else:
                # å•ä¸€ç±»å‹ï¼šä½¿ç”¨å¯¹åº”åç¼€
                fallback_suffixes = type_specific_suffixes.get(knowledge_type, type_specific_suffixes["all"])

                # æ ¹æ®é‡è¯•æ¬¡æ•°é€‰æ‹©ä¸åŒçš„åç¼€
                suffix_index = (retry_count - 1) % len(fallback_suffixes)
                fallback_query = f"{question[:50]} {fallback_suffixes[suffix_index]}"

                new_queries = [fallback_query]
                print(f"[TRANSFORM] Fallback query (type={knowledge_type}): {new_queries}")

    # æ ¹æ®é‡è¯•æ¬¡æ•°å†³å®šæ˜¯å¦è·³è¿‡å®¡æ‰¹
    # retry_count >= 3 æ—¶è‡ªåŠ¨ç”Ÿæˆï¼Œä¸å†æ˜¾ç¤ºå®¡æ‰¹å¡ç‰‡
    max_retries_before_auto = 3
    skip_approval = retry_count >= max_retries_before_auto

    if skip_approval:
        print(f"[TRANSFORM] Max retries ({max_retries_before_auto}) reached, will auto-generate")

    return {
        "rewritten_queries": new_queries,
        "retry_count": retry_count,  # è¿”å›æ›´æ–°åçš„é‡è¯•è®¡æ•°
        "skip_hitl": skip_approval  # è¶…è¿‡3æ¬¡è‡ªåŠ¨ç”Ÿæˆï¼Œå¦åˆ™å†æ¬¡å®¡æ‰¹
    }

def check_answer_quality(state: MarketingState) -> Dict[str, Any]:
    """
    å¹»è§‰æ£€æµ‹ä¸è´¨é‡è¯„ä¼°èŠ‚ç‚¹
    """
    print("[CHECK] Checking answer quality")
    
    question = state.get("question")
    documents = state.get('retrieved_docs', '')
    generation = state.get("generation")

    # 1. Hallucination Check
    llm_hallucinations = llm.with_structured_output(GradeHallucinations)

    # NOTE: é˜¿é‡Œäº‘ API è¦æ±‚ä½¿ç”¨ json_object response_format æ—¶ï¼Œæ¶ˆæ¯ä¸­å¿…é¡»åŒ…å« "json" å…³é”®è¯
    # NOTE: å¿…é¡»åœ¨ prompt ä¸­æ˜ç¡®æŒ‡å®š JSON å­—æ®µåï¼Œå¦åˆ™ LLM å¯èƒ½è¿”å›ä¸åŒ¹é…çš„å­—æ®µå
    hallucination_prompt = """You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts.
Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.

You MUST respond with a JSON object containing EXACTLY this field:
{"binary_score": "<yes|no>"}"""

    messages = [
        SystemMessage(content=hallucination_prompt),
        HumanMessage(content=f"Set of facts:\n\n{documents}\n\nLLM Generation: {generation}")
    ]
    
    try:
        res_hallucination = llm_hallucinations.invoke(messages)
        hallucination_grade = res_hallucination.binary_score
    except:
        hallucination_grade = "yes"

    print(f"[CHECK] Hallucination Grade: {hallucination_grade}")

    if hallucination_grade == 'yes':
        # 2. Answer Quality Check
        llm_answer = llm.with_structured_output(GradeAnswer)

        # NOTE: é˜¿é‡Œäº‘ API è¦æ±‚ä½¿ç”¨ json_object response_format æ—¶ï¼Œæ¶ˆæ¯ä¸­å¿…é¡»åŒ…å« "json" å…³é”®è¯
        # NOTE: å¿…é¡»åœ¨ prompt ä¸­æ˜ç¡®æŒ‡å®š JSON å­—æ®µåï¼Œå¦åˆ™ LLM å¯èƒ½è¿”å›ä¸åŒ¹é…çš„å­—æ®µå
        answer_prompt = """You are a grader assessing whether an answer addresses / resolves a query.
Give a binary score 'yes' or 'no'. 'Yes' means that the answer resolves the query.

You MUST respond with a JSON object containing EXACTLY this field:
{"binary_score": "<yes|no>"}"""
        
        messages = [
            SystemMessage(content=answer_prompt),
            HumanMessage(content=f"User Query: {question}\n\n LLM Generation: {generation}")
        ]
        
        try:
            res_answer = llm_answer.invoke(messages)
            answer_grade = res_answer.binary_score
        except:
            answer_grade = "yes"
            
        print(f"[CHECK] Answer Grade: {answer_grade}")
        
        return {
            "hallucination_grade": hallucination_grade,
            "answer_grade": answer_grade
        }
    else:
        return {
            "hallucination_grade": hallucination_grade,
            "answer_grade": "no"
        }

# =============================================================================
# Web Search Node (White-box Reuse)
# å¤ç”¨æ¥æº: menonpg/agentic_search_openai_langgraph, psykick-21/deep-research
# =============================================================================

def web_search_node(state: MarketingState) -> Dict[str, Any]:
    """
    Web Search èŠ‚ç‚¹: æ”¯æŒä¸¤ç§æ¨¡å¼
    1. çº¯ Web æœç´¢: å½“çŸ¥è¯†åº“å®Œå…¨ä¸ç›¸å…³æ—¶
    2. è¡¥å……æ··åˆ: å½“çŸ¥è¯†åº“éƒ¨åˆ†ç›¸å…³æ—¶ï¼Œåˆå¹¶ä¸¤ä¸ªæ¥æº

    å¤ç”¨ç­–ç•¥:
    - ç›´æ¥å¤ç”¨ langchain_community.tools.DuckDuckGoSearchResults
    - æ”¯æŒå¯é€‰çš„ Tavily (éœ€è¦ API Key)
    """
    # å¢åŠ é‡è¯•è®¡æ•°ï¼ˆWeb æœç´¢ä¹Ÿè®¡å…¥é‡è¯•æ¬¡æ•°ï¼‰
    current_retry = state.get("retry_count", 0)
    retry_count = current_retry + 1
    print(f"[WEB_SEARCH] Initiating web search... (retry_count: {current_retry} -> {retry_count})")

    question = state.get("question", "")
    rewritten_queries = state.get("rewritten_queries", [])
    kb_docs = state.get("kb_docs", "")  # è·å–å·²æœ‰çš„çŸ¥è¯†åº“æ–‡æ¡£
    current_grade = state.get("grade", "no")

    # è°ƒè¯•ä¿¡æ¯
    print(f"[WEB_SEARCH] Current grade: {current_grade}")
    print(f"[WEB_SEARCH] KB docs available: {bool(kb_docs and kb_docs.strip())}")
    if kb_docs:
        print(f"[WEB_SEARCH] KB docs preview: {kb_docs[:200]}...")

    # ä½¿ç”¨é‡å†™åçš„æŸ¥è¯¢æˆ–åŸå§‹é—®é¢˜
    search_query = rewritten_queries[-1] if rewritten_queries else question

    # åˆå§‹åŒ–æœç´¢å·¥å…· (White-box Reuse: langchain_community)
    use_tavily = settings.USE_TAVILY and settings.TAVILY_API_KEY

    try:
        if use_tavily:
            from langchain_community.tools.tavily_search import TavilySearchResults
            search_tool = TavilySearchResults(
                max_results=5,
                search_depth="advanced",
                include_answer=True
            )
            print("[WEB_SEARCH] Using Tavily Search API")
        else:
            search_tool = DuckDuckGoSearchResults(
                max_results=5,
                output_format="list"
            )
            print("[WEB_SEARCH] Using DuckDuckGo Search")

        # æ‰§è¡Œæœç´¢
        results = search_tool.invoke(search_query)

        # æ ¼å¼åŒ–æœç´¢ç»“æœ
        if isinstance(results, list):
            web_docs = []
            for i, r in enumerate(results, 1):
                if isinstance(r, dict):
                    title = r.get("title", "Untitled")
                    snippet = r.get("snippet", r.get("body", r.get("content", "")))
                    link = r.get("link", r.get("url", ""))
                    web_docs.append(f"[Web Source {i}] {title}\n{snippet}\nURL: {link}")
                else:
                    web_docs.append(f"[Web Source {i}] {str(r)}")
            web_results = "\n\n".join(web_docs)
        else:
            web_results = str(results)

        print(f"[WEB_SEARCH] Retrieved {len(results) if isinstance(results, list) else 1} results")

        # å†³å®šæ˜¯æ··åˆæ¨¡å¼è¿˜æ˜¯çº¯ Web æ¨¡å¼
        if current_grade == "partial" and kb_docs:
            # è¡¥å……æ··åˆæ¨¡å¼: åˆå¹¶çŸ¥è¯†åº“å’Œ Web ç»“æœ
            print("[WEB_SEARCH] Hybrid mode - Merging KB docs with Web results")
            combined_docs = f"""## Knowledge Base Documents (Internal Sources)

{kb_docs}

---

## Web Search Supplement for: {search_query}

{web_results}"""
            source_type = "hybrid"
        else:
            # çº¯ Web æ¨¡å¼
            combined_docs = f"## Web Search Results for: {search_query}\n\n{web_results}"
            source_type = "web_search"

        # æ ¹æ®é‡è¯•æ¬¡æ•°å†³å®šæ˜¯å¦è·³è¿‡å®¡æ‰¹ï¼ˆä¸ transform_query_node é€»è¾‘ä¸€è‡´ï¼‰
        max_retries_before_auto = 3
        skip_approval = retry_count >= max_retries_before_auto

        if skip_approval:
            print(f"[WEB_SEARCH] Max retries ({max_retries_before_auto}) reached, will auto-generate")

        return {
            "retrieved_docs": combined_docs,
            "web_docs": web_results,
            "source_type": source_type,
            "grade": "yes",  # æœç´¢å®Œæˆï¼Œå¯ä»¥è¿›å…¥ç”Ÿæˆ
            "retry_count": retry_count,  # æ›´æ–°é‡è¯•è®¡æ•°
            "skip_hitl": skip_approval  # è¶…è¿‡3æ¬¡è‡ªåŠ¨ç”Ÿæˆ
        }

    except Exception as e:
        print(f"[WEB_SEARCH] Error: {e}")
        # å¦‚æœ Web æœç´¢å¤±è´¥ä½†æœ‰çŸ¥è¯†åº“æ–‡æ¡£ï¼Œä»ç„¶ä½¿ç”¨çŸ¥è¯†åº“
        if kb_docs:
            return {
                "retrieved_docs": kb_docs,
                "source_type": "knowledge_base",
                "grade": "yes"
            }
        return {
            "retrieved_docs": f"Web search failed: {str(e)}",
            "source_type": "fallback",
            "grade": "yes"
        }

# =============================================================================
# Routers
# =============================================================================

def check_approval(state: MarketingState) -> str:
    """
    è·¯ç”±: æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ‰¹å‡†ç”Ÿæˆ

    ç”¨æˆ·åé¦ˆé€‰é¡¹:
    - "approved": æ‰¹å‡† -> ç”Ÿæˆå›ç­”
    - "rejected": æ‹’ç» -> é‡æ–°æ£€ç´¢ï¼ˆtransform_queryï¼‰
    - "web_search": æ‹’ç»å¹¶ä½¿ç”¨ Web æœç´¢ -> ç›´æ¥è¿›è¡Œ Web æœç´¢
    """
    feedback = state.get("user_feedback")
    if feedback == "approved":
        print("[ROUTER] User approved -> Generate")
        return "generate"
    elif feedback == "web_search":
        print("[ROUTER] User requested Web Search -> Web Search")
        return "web_search"
    else:
        print("[ROUTER] User rejected -> Transform Query")
        return "transform_query"

def should_generate(state: MarketingState) -> str:
    """
    è·¯ç”±: å†³å®šæ˜¯ç”Ÿæˆå›ç­”ã€é‡å†™æŸ¥è¯¢è¿˜æ˜¯è§¦å‘ Web æœç´¢

    ç­–ç•¥ (CRAG + Web Search Fallback + è¡¥å……æ··åˆ):
    - force_web_search == True -> ç›´æ¥è¿›è¡Œ Web æœç´¢
    - grade == 'yes' -> ç›´æ¥ç”Ÿæˆ
    - grade == 'partial' -> è¡¥å…… Web æœç´¢ï¼ˆæ··åˆæ¨¡å¼ï¼‰
    - retry_count >= 2 -> è§¦å‘ Web æœç´¢
    - å¦åˆ™ -> é‡å†™æŸ¥è¯¢
    """
    grade = state.get("grade")
    retry_count = state.get("retry_count", 0)
    force_web_search = state.get("force_web_search", False)
    max_retries_before_web = 2  # 2æ¬¡çŸ¥è¯†åº“é‡è¯•åè§¦å‘ Web æœç´¢
    max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

    # ç”¨æˆ·æ˜ç¡®è¯·æ±‚ Web æœç´¢
    if force_web_search:
        print("[ROUTER] User explicitly requested Web Search -> Web Search")
        return "web_search"

    if grade == "yes":
        print("[ROUTER] Documents relevant -> Generate")
        return "generate"
    elif grade == "partial":
        # éƒ¨åˆ†ç›¸å…³ï¼šè§¦å‘è¡¥å…… Web æœç´¢ï¼ˆæ··åˆæ¨¡å¼ï¼‰
        print("[ROUTER] Documents partially relevant -> Supplement with Web Search (Hybrid)")
        return "web_search"
    elif retry_count >= max_retries_before_web and retry_count < max_retries:
        print(f"[ROUTER] KB retries exhausted ({retry_count}) -> Web Search")
        return "web_search"
    elif retry_count >= max_retries:
        print(f"[ROUTER] Max retries ({max_retries}) reached -> Force Generate (Fallback)")
        return "generate"  # è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œå¼ºåˆ¶è¿›å…¥ç”Ÿæˆé˜¶æ®µ
    else:
        print(f"[ROUTER] Documents irrelevant (retry {retry_count + 1}/{max_retries}) -> Transform Query")
        return "transform_query"

def check_hallucination_router(state: MarketingState) -> str:
    """
    è·¯ç”±: å†³å®šæ˜¯ç»“æŸã€é‡å†™æŸ¥è¯¢è¿˜æ˜¯é‡æ–°ç”Ÿæˆ
    æ·»åŠ é‡è¯•é™åˆ¶ï¼Œé˜²æ­¢æ— é™å¾ªç¯
    """
    hallucination_grade = state.get("hallucination_grade")
    answer_grade = state.get("answer_grade")
    retry_count = state.get("retry_count", 0)
    max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

    if hallucination_grade == "yes":
        if answer_grade == "yes":
            print("[ROUTER] Answer is good -> END")
            return "useful"  # Map to learning node in graph
        elif retry_count >= max_retries:
            print(f"[ROUTER] Max retries ({max_retries}) reached -> Force END (Fallback)")
            return "useful"  # è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œå¼ºåˆ¶ç»“æŸ
        else:
            print(f"[ROUTER] Answer not useful (retry {retry_count}/{max_retries}) -> Transform Query")
            return "not useful"
    else:
        if retry_count >= max_retries:
            print(f"[ROUTER] Hallucination detected but max retries reached -> Force END")
            return "useful"  # è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œå¼ºåˆ¶ç»“æŸ
        print("[ROUTER] Hallucination detected -> Not Supported")
        return "not supported"

"""
AI è¥é”€è€å¸ˆ - CRAG èŠ‚ç‚¹å®žçŽ° (White-box Reuse)

å¤ç”¨æ¥æº: Agentic-RAG-Ollama/scripts/nodes.py
é€‚é…:
1. æ›¿æ¢ ChatOllama ä¸º DeepSeek (OpenAI Compatible)
2. æ›¿æ¢é‡‘èž Prompt ä¸ºè¥é”€ Prompt
3. é›†æˆé¡¹ç›®å†…éƒ¨ RAGPipeline
"""

from typing import List, Annotated, Dict, Any, Optional, Literal
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage
from pydantic import BaseModel, Field
import operator
import os
from langgraph.types import interrupt
from openai import OpenAI
import instructor

from src.agents.marketing.llm import llm  # ä½¿ç”¨é¡¹ç›®ç»Ÿä¸€é…ç½®çš„ DeepSeek LLM
from src.services.rag.multimodal_pipeline import MultimodalRAGPipeline  # ç»Ÿä¸€ä½¿ç”¨å¤šæ¨¡æ€ Pipeline
from src.agents.marketing.learning import reflect_on_feedback
from langgraph.store.base import BaseStore
from config.settings import settings


def keep_latest(current: Any, new: Any) -> Any:
    """
    Reducer that keeps the latest (newest) value, used for flag fields.
    Handles initial state where current might be None.
    """
    if new is not None:
        return new
    if current is not None:
        return current
    return False  # Default for bool fields

# =============================================================================
# Web Search Tools (White-box Reuse: langchain_community)
# å¤ç”¨æ¥æº: menonpg/agentic_search_openai_langgraph
# =============================================================================
from langchain_community.tools import DuckDuckGoSearchResults

# =============================================================================
# State å®šä¹‰
# =============================================================================

class MarketingState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]
    question: str
    retrieved_docs: str  # æœ€ç»ˆåˆå¹¶åŽçš„æ–‡æ¡£ï¼ˆç”¨äºŽç”Ÿæˆï¼‰
    kb_docs: str  # çŸ¥è¯†åº“æ£€ç´¢çš„æ–‡æ¡£
    web_docs: str  # Web æœç´¢çš„æ–‡æ¡£
    rewritten_queries: List[str]
    generation: str
    grade: str  # 'yes', 'partial', 'no' - æ·»åŠ  partial ç”¨äºŽè¡¥å……æ··åˆ
    hallucination_grade: str # 'yes' or 'no'
    answer_grade: str # 'yes' or 'no'
    retry_count: int
    user_feedback: Optional[str]
    source_type: Literal["knowledge_base", "web_search", "hybrid", "fallback"]  # æ·»åŠ  hybrid ç±»åž‹
    force_web_search: Annotated[bool, keep_latest]  # ä½¿ç”¨ reducer ç¡®ä¿å€¼è¢«æ­£ç¡®ä¼ é€’

# =============================================================================
# Pydantic Schemas (å¤ç”¨è‡ª Agentic-RAG)
# =============================================================================

class GradeDocuments(BaseModel):
    """Relevance score for retrieved documents."""
    relevance_score: str = Field(
        description="Document relevance: 'yes' (highly relevant), 'partial' (somewhat relevant, may need supplement), 'no' (not relevant)"
    )

class GradeHallucinations(BaseModel):
    """Binary score for hallucination present in generation answer."""
    binary_score: str = Field(description="Answer is grounded with the facts for the query, 'yes' or 'no'")

class GradeAnswer(BaseModel):
    """Binary score to assess answer addresses query."""
    binary_score: str = Field(description="Answer addresses the query, 'yes' or 'no'")

class SearchQueries(BaseModel):
    """Search queries for retrieving missing information."""
    search_queries: list[str] = Field(description="1-3 search queries to retrieve the missing information.")


class KnowledgeTypeClassification(BaseModel):
    """
    çŸ¥è¯†ç±»åž‹åˆ†ç±»ç»“æžœ
    å¤ç”¨é¡¹ç›® LLM è¿›è¡Œæ„å›¾åˆ†ç±»ï¼Œå†³å®šæ£€ç´¢å“ªä¸ªçŸ¥è¯†å­åº“
    """
    knowledge_type: str = Field(
        description="Knowledge type: 'product_raw' (product features/specs), 'sales_raw' (sales skills/objection handling), 'material' (copywriting/marketing materials), 'conclusion' (best practices/conclusions), 'all' (search all types)"
    )
    reasoning: str = Field(description="Brief reasoning for this classification")


# =============================================================================
# çŸ¥è¯†ç±»åž‹å®šä¹‰ (ä¸Ž server.py ä¿æŒä¸€è‡´)
# =============================================================================
KNOWLEDGE_TYPES = {
    "product_raw": "äº§å“åŽŸå§‹èµ„æ–™",
    "sales_raw": "é”€å”®ç»éªŒ/è¯æœ¯",
    "material": "æ–‡æ¡ˆ/ç´ æ",
    "conclusion": "ç»“è®ºåž‹çŸ¥è¯†",
}

# =============================================================================
# Helper Functions
# =============================================================================

def get_latest_user_query(messages: List[BaseMessage]) -> str:
    for message in reversed(messages):
        if isinstance(message, HumanMessage):
            return message.content
    return messages[0].content if messages else ''


def classify_knowledge_type(question: str) -> str:
    """
    ä½¿ç”¨ Instructor + LLM åˆ†ç±»ç”¨æˆ·é—®é¢˜æ‰€éœ€çš„çŸ¥è¯†ç±»åž‹

    Instructor æä¾›:
    - è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼ˆéªŒè¯å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•ï¼‰
    - Pydantic ç±»åž‹éªŒè¯
    - å¤šæ¨¡å¼é€‚é…ï¼ˆMD_JSON æ¨¡å¼å…¼å®¹é˜¿é‡Œäº‘ç™¾ç‚¼ï¼‰

    Returns:
        str: çŸ¥è¯†ç±»åž‹ ('product_raw', 'sales_raw', 'material', 'conclusion', 'all')
    """
    # ç§»é™¤å±€éƒ¨ load_dotenvï¼Œä½¿ç”¨å…¨å±€ settings
    from openai import OpenAI

    # å®šä¹‰ç»“æž„åŒ–è¾“å‡º Schema
    class KnowledgeClassification(BaseModel):
        """çŸ¥è¯†ç±»åž‹åˆ†ç±»ç»“æžœ"""
        knowledge_type: Literal["product_raw", "sales_raw", "material", "conclusion", "all"] = Field(
            description="çŸ¥è¯†ç±»åž‹: product_raw(äº§å“èµ„æ–™), sales_raw(é”€å”®è¯æœ¯), material(æ–‡æ¡ˆç´ æ), conclusion(ç»“è®ºçŸ¥è¯†), all(ç»¼åˆ)"
        )

    system_prompt = """ä½ æ˜¯ä¸€ä¸ªè¥é”€çŸ¥è¯†åˆ†ç±»ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œåˆ¤æ–­åº”è¯¥æ£€ç´¢å“ªç§ç±»åž‹çš„çŸ¥è¯†åº“ã€‚

çŸ¥è¯†åº“ç±»åž‹ï¼š
- product_raw: äº§å“åŠŸèƒ½ã€è§„æ ¼ã€ç‰¹æ€§ã€æŠ€æœ¯å‚æ•°ç­‰äº§å“åŽŸå§‹èµ„æ–™
- sales_raw: é”€å”®æŠ€å·§ã€è¯æœ¯ã€å®¢æˆ·å¼‚è®®å¤„ç†ã€æˆäº¤ç­–ç•¥ç­‰é”€å”®ç»éªŒ
- material: å®£ä¼ æ–‡æ¡ˆã€è¥é”€ç´ æã€å¹¿å‘Šè¯­ã€æŽ¨å¹¿å†…å®¹ç­‰
- conclusion: æœ€ä½³å®žè·µã€ç­–ç•¥æ€»ç»“ã€æ–¹æ³•è®ºã€ç»“è®ºæ€§çŸ¥è¯†
- all: é—®é¢˜æ¶‰åŠå¤šä¸ªç±»åž‹ï¼Œéœ€è¦ç»¼åˆæ£€ç´¢

åˆ†ç±»åŽŸåˆ™ï¼š
1. é—®äº§å“æ˜¯ä»€ä¹ˆã€æœ‰ä»€ä¹ˆåŠŸèƒ½ â†’ product_raw
2. é—®æ€Žä¹ˆå–ã€æ€Žä¹ˆè¯´æœå®¢æˆ·ã€æ€Žä¹ˆå¤„ç†å¼‚è®® â†’ sales_raw
3. éœ€è¦æ–‡æ¡ˆã€ç´ æã€å®£ä¼ å†…å®¹ â†’ material
4. é—®æœ€ä½³å®žè·µã€ç­–ç•¥å»ºè®®ã€æ–¹æ³•è®º â†’ conclusion
5. é—®é¢˜æ¨¡ç³Šæˆ–æ¶‰åŠå¤šæ–¹é¢ â†’ all"""

    try:
        # åˆ›å»º Instructor å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼ OpenAI å…¼å®¹æŽ¥å£ï¼‰
        client = instructor.from_openai(
            OpenAI(
                api_key=settings.OPENAI_API_KEY,
                base_url=settings.OPENAI_API_BASE,
            ),
            mode=instructor.Mode.MD_JSON  # ä½¿ç”¨ MD_JSON æ¨¡å¼ï¼Œå…¼å®¹æ€§æœ€å¥½
        )

        # è°ƒç”¨ LLM èŽ·å–ç»“æž„åŒ–è¾“å‡º
        result = client.chat.completions.create(
            model=settings.DEFAULT_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ç”¨æˆ·é—®é¢˜: {question}"}
            ],
            response_model=KnowledgeClassification,
            max_retries=2  # è‡ªåŠ¨é‡è¯• 2 æ¬¡
        )

        print(f"[CLASSIFY/Instructor] Question: '{question[:50]}...' -> Type: {result.knowledge_type}")
        return result.knowledge_type

    except Exception as e:
        print(f"[CLASSIFY/Instructor] Error: {e}, fallback to 'all'")
        return "all"

def detect_web_search_intent(question: str) -> bool:
    """
    æ£€æµ‹ç”¨æˆ·æ˜¯å¦æ˜Žç¡®è¯·æ±‚è¿›è¡Œ Web æœç´¢ï¼ˆè”ç½‘æœç´¢ï¼‰

    æ³¨æ„ï¼šä»…å½“ç”¨æˆ·æ˜Žç¡®è¡¨ç¤ºè¦è¿›è¡Œ"è”ç½‘"/"ç½‘ç»œ"æœç´¢æ—¶æ‰è¿”å›ž True
    æ™®é€šçš„"æœç´¢xxx"åº”è¯¥ä½¿ç”¨çŸ¥è¯†åº“æ£€ç´¢ï¼Œè€Œéž Web æœç´¢
    """
    # æ˜Žç¡®çš„è”ç½‘æœç´¢å…³é”®è¯ï¼ˆå¿…é¡»åŒ…å«"è”ç½‘"ã€"ç½‘ç»œ"ã€"äº’è”ç½‘"ç­‰è¯ï¼‰
    explicit_web_keywords = [
        "è”ç½‘æœç´¢", "ç½‘ç»œæœç´¢", "åœ¨çº¿æœç´¢", "æœç´¢ç½‘ä¸Š", "æœç´¢äº’è”ç½‘",
        "web search", "search online", "search the web", "internet search",
        "æŸ¥ä¸€ä¸‹ç½‘ä¸Š", "åŽ»ç½‘ä¸Šæ‰¾", "ä¸Šç½‘æŸ¥", "ç™¾åº¦ä¸€ä¸‹", "è°·æ­Œä¸€ä¸‹",
        "å¸®æˆ‘è”ç½‘", "ç”¨ç½‘ç»œ", "ä»Žç½‘ä¸Š"
    ]

    # æ—¶æ•ˆæ€§å…³é”®è¯ï¼ˆè¡¨ç¤ºéœ€è¦æœ€æ–°ä¿¡æ¯ï¼‰
    realtime_keywords = [
        "æœ€æ–°", "å®žæ—¶", "å½“å‰", "ä»Šå¤©çš„æ–°é—»", "æœ€è¿‘çš„æ–°é—»",
        "latest news", "current news", "real-time", "today's"
    ]

    question_lower = question.lower()

    # æ£€æŸ¥æ˜Žç¡®çš„è”ç½‘æœç´¢æ„å›¾
    if any(keyword in question_lower for keyword in explicit_web_keywords):
        return True

    # æ£€æŸ¥æ—¶æ•ˆæ€§æ„å›¾ï¼ˆä½†éœ€è¦æ›´ä¸¥æ ¼çš„åŒ¹é…ï¼‰
    if any(keyword in question_lower for keyword in realtime_keywords):
        return True

    return False

# =============================================================================
# Nodes å®žçŽ° (Adapted)
# =============================================================================

def retrieve_node(state: MarketingState) -> Dict[str, Any]:
    """
    æ£€ç´¢èŠ‚ç‚¹: ä»ŽçŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£
    æ”¯æŒ:
    1. å‰ç«¯å¼€å…³æŽ§åˆ¶çš„ Web æœç´¢ (force_web_search ç›´æŽ¥ä¼ å…¥)
    2. æ™ºèƒ½æ„å›¾æ£€æµ‹ (ä»…ä½œä¸ºåŽå¤‡)
    3. æŒ‰çŸ¥è¯†ç±»åž‹åˆ†ç±»æ£€ç´¢ (knowledge_type filter)
    """
    print("[RETRIEVE] Fetching documents...")

    # èŽ·å–é—®é¢˜
    question = state.get("question")
    if not question:
        question = get_latest_user_query(state.get("messages", []))

    # æ£€æŸ¥å‰ç«¯å¼€å…³æ˜¯å¦å·²å¯ç”¨ Web æœç´¢
    force_web_search = state.get("force_web_search", False)

    # å¦‚æžœå‰ç«¯æœªå¼€å¯ï¼Œæ‰æ£€æµ‹æ„å›¾ï¼ˆä½œä¸ºåŽå¤‡ï¼‰
    if not force_web_search:
        force_web_search = detect_web_search_intent(question)

    # åˆ†ç±»é—®é¢˜ç±»åž‹ï¼Œå†³å®šæ£€ç´¢å“ªä¸ªçŸ¥è¯†å­åº“
    knowledge_type = classify_knowledge_type(question)
    metadata_filter = None if knowledge_type == "all" else {"knowledge_type": knowledge_type}
    print(f"[RETRIEVE] Knowledge type: {knowledge_type}, filter: {metadata_filter}")

    if force_web_search:
        print(f"[RETRIEVE] Web search mode enabled for: '{question}'")

        # æ™ºèƒ½æ··åˆæ¨¡å¼ï¼šå…ˆå°è¯•ä»ŽçŸ¥è¯†åº“æ£€ç´¢
        pipeline = MultimodalRAGPipeline()
        try:
            docs = pipeline.retrieve(question, k=3, metadata_filter=metadata_filter)

            if docs and any(d.page_content.strip() for d in docs):
                # çŸ¥è¯†åº“æœ‰ç›¸å…³å†…å®¹ â†’ è§¦å‘æ··åˆæ¨¡å¼
                print(f"[RETRIEVE] Found {len(docs)} KB docs, triggering hybrid mode")

                # æ ¼å¼åŒ–çŸ¥è¯†åº“æ–‡æ¡£
                doc_texts = []
                for i, d in enumerate(docs, 1):
                    source_name = d.metadata.get('original_filename', 'Unknown Source')
                    doc_texts.append(f"[Source {i}] (File: {source_name}):\n{d.page_content}")

                kb_content = "\n\n".join(doc_texts)
                kb_formatted = f"## Query: {question}\n\n### Retrieved Documents:\n{kb_content}"

                return {
                    'retrieved_docs': kb_formatted,
                    'kb_docs': kb_formatted,
                    'question': question,
                    'force_web_search': True,
                    'grade': 'partial'  # è§¦å‘æ··åˆæœç´¢
                }
            else:
                # çŸ¥è¯†åº“æ— ç›¸å…³å†…å®¹ â†’ çº¯ Web æœç´¢
                print("[RETRIEVE] No relevant KB docs, triggering pure web search")
                return {
                    'retrieved_docs': '',
                    'kb_docs': '',
                    'question': question,
                    'force_web_search': True,
                    'grade': 'no'  # è§¦å‘çº¯ Web æœç´¢
                }
        except Exception as e:
            print(f"[RETRIEVE] KB search error: {e}, fallback to pure web search")
            return {
                'retrieved_docs': '',
                'kb_docs': '',
                'question': question,
                'force_web_search': True,
                'grade': 'no'
            }

    rewritten_queries = state.get('rewritten_queries', [])
    queries_to_search = rewritten_queries if rewritten_queries else [question]

    # åˆå§‹åŒ–å¤šæ¨¡æ€ RAG Pipeline
    pipeline = MultimodalRAGPipeline()

    all_results = []
    for idx, search_query in enumerate(queries_to_search, 1):
        print(f"[RETRIEVE] Query {idx}: {search_query}")

        # Extract keywords for BM25 Re-ranking (Simple strategy: split by space, filter short words)
        # In a full implementation, we might use an LLM to extract keywords, but this is efficient.
        keywords = [w for w in search_query.split() if len(w) > 2]

        # ä½¿ç”¨ MultimodalRAGPipeline è¿›è¡Œæ£€ç´¢ (Hybrid Search with Re-ranking + Knowledge Type Filter)
        docs = pipeline.retrieve(search_query, k=3, keywords=keywords, metadata_filter=metadata_filter)

        # æ ¼å¼åŒ–æ–‡æ¡£å†…å®¹ with Source IDs for citation
        doc_texts = []
        for i, d in enumerate(docs, 1):
            source_name = d.metadata.get('original_filename', 'Unknown Source')
            doc_texts.append(f"[Source {i}] (File: {source_name}):\n{d.page_content}")

        doc_txt = "\n\n".join(doc_texts)
        text = f"## Query {idx}: {search_query}\n\n### Retrieved Documents:\n{doc_txt}"
        all_results.append(text)

    combined_result = "\n\n".join(all_results)

    return {
        'retrieved_docs': combined_result,
        'kb_docs': combined_result,  # åŒæ—¶å­˜å‚¨åˆ° kb_docs
        'question': question,
        'source_type': 'knowledge_base'
    }

def grade_documents_node(state: MarketingState) -> Dict[str, Any]:
    """
    æ–‡æ¡£è¯„ä¼°èŠ‚ç‚¹: åˆ¤æ–­æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦ä¸Žé—®é¢˜ç›¸å…³ (Marketing Context)
    æ”¯æŒä¸‰çº§è¯„åˆ†: yes (å®Œå…¨ç›¸å…³), partial (éƒ¨åˆ†ç›¸å…³ï¼Œéœ€è¦è¡¥å……), no (ä¸ç›¸å…³)
    """
    print("[GRADE] Evaluating document relevance")

    # æ£€æŸ¥æ˜¯å¦å·²ç»ç”± retrieve_node è®¾ç½®äº† grade (æ™ºèƒ½æ··åˆæ¨¡å¼)
    existing_grade = state.get("grade")
    if existing_grade == "partial":
        # retrieve_node å·²åˆ¤æ–­ä¸ºæ··åˆæ¨¡å¼ï¼Œç›´æŽ¥ä¿æŒ
        print("[GRADE] Using pre-set grade from retrieve_node: partial (hybrid mode)")
        return {'grade': 'partial'}

    # å¦‚æžœç”¨æˆ·æ˜Žç¡®è¯·æ±‚ Web æœç´¢ä¸” grade='no'ï¼Œä¿æŒ force_web_search æ ‡å¿—
    force_web_search = state.get("force_web_search", False)
    if force_web_search and existing_grade == "no":
        print("[GRADE] Skipping - User explicitly requested web search (pure mode)")
        return {'grade': 'no', 'force_web_search': True}

    question = state.get("question")
    documents = state.get('retrieved_docs', '')

    if not documents:
        return {'grade': 'no'}

    llm_structured = llm.with_structured_output(GradeDocuments)

    # æ›´æ–°åŽçš„ Prompt æ”¯æŒä¸‰çº§è¯„åˆ†
    system_prompt = """You are a senior marketing strategist assessing the relevance of retrieved documents to a user's marketing question.

GRADING SCALE:
- 'yes': Documents are HIGHLY relevant and contain sufficient information to fully answer the query
- 'partial': Documents are SOMEWHAT relevant but may need supplementation with additional information (e.g., missing recent data, incomplete coverage)
- 'no': Documents are NOT relevant to the query at all

GUIDELINES:
- If documents contain core marketing concepts directly related to the query â†’ 'yes'
- If documents are tangentially related or cover only part of the query â†’ 'partial'
- If documents are completely unrelated to marketing or the specific query â†’ 'no'

Return one of: 'yes', 'partial', 'no'"""

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"Retrieved Document: {documents}\n\nUser query: {question}")
    ]

    try:
        response = llm_structured.invoke(messages)
        grade = response.relevance_score.lower()
        # æ ‡å‡†åŒ–è¾“å‡º
        if grade not in ['yes', 'partial', 'no']:
            grade = 'yes' if 'yes' in grade else ('partial' if 'partial' in grade else 'no')
    except Exception as e:
        print(f"[GRADE] Error: {e}")
        grade = "yes"  # Fallback

    print(f"[GRADE] Relevance: {grade}")

    if grade == 'yes':
        return {'grade': 'yes'}
    elif grade == 'partial':
        # éƒ¨åˆ†ç›¸å…³ï¼šä¿ç•™çŸ¥è¯†åº“æ–‡æ¡£ï¼Œè§¦å‘è¡¥å……æœç´¢
        return {'grade': 'partial'}
    else:
        return {'grade': 'no', 'retrieved_docs': ''}  # Clear docs if irrelevant

def human_approval_node(state: MarketingState) -> Dict[str, Any]:
    """
    HITL Approval Node: Interrupts execution to request user approval.
    ä¼ é€’ä¸Šä¸‹æ–‡ä¿¡æ¯ç»™ç”¨æˆ·å®¡æ ¸ï¼ŒåŒ…æ‹¬æ•°æ®æ¥æºç±»åž‹
    """
    print("[HITL] Requesting human approval")

    question = state.get("question", "")
    documents = state.get("retrieved_docs", "")
    source_type = state.get("source_type", "unknown")

    # æ ¹æ®æ¥æºç±»åž‹ç”Ÿæˆä¸åŒçš„å®¡æ ¸æ¶ˆæ¯
    source_labels = {
        "knowledge_base": "ðŸ“š çŸ¥è¯†åº“",
        "web_search": "ðŸŒ Web æœç´¢",
        "hybrid": "ðŸ“š+ðŸŒ æ··åˆæ¥æºï¼ˆçŸ¥è¯†åº“ + Web è¡¥å……ï¼‰",
        "fallback": "âš ï¸ å¤‡ç”¨"
    }
    source_label = source_labels.get(source_type, source_type)

    # ä¼ é€’å®¡æ ¸ä¸Šä¸‹æ–‡ç»™å‰ç«¯
    review_context = {
        "question": question,
        "retrieved_docs": documents[:800] if documents else "æ— ç›¸å…³æ–‡æ¡£",  # å¢žåŠ æˆªæ–­é•¿åº¦
        "source_type": source_type,
        "source_label": source_label,
        "message": f"æ•°æ®æ¥æº: {source_label}\nè¯·å®¡æ ¸æ£€ç´¢åˆ°çš„å†…å®¹æ˜¯å¦ç›¸å…³ï¼Œç¡®è®¤åŽå°†åŸºäºŽè¿™äº›å†…å®¹ç”Ÿæˆå›žç­”ã€‚"
    }

    # Interrupt execution and wait for user input
    user_input = interrupt(review_context)

    print(f"[HITL] User input: {user_input}")

    return {"user_feedback": user_input}

async def learning_node(state: MarketingState, store: BaseStore) -> Dict[str, Any]:
    """
    å­¦ä¹ èŠ‚ç‚¹: åˆ†æžç”¨æˆ·åé¦ˆå¹¶æ›´æ–°åå¥½è§„åˆ™
    """
    print("[LEARNING] Analyzing feedback...")
    
    feedback = state.get("user_feedback")
    messages = state.get("messages")
    
    if not feedback:
        return {}
        
    # Get current rules
    namespace = ("marketing_preferences",)
    key = "user_rules"
    
    # Note: store.aget returns an Item or None
    current_rules_item = await store.aget(namespace, key)
    current_rules = current_rules_item.value["rules"] if current_rules_item and "rules" in current_rules_item.value else "*no rules yet*"
    
    # Reflect
    new_rules = await reflect_on_feedback(messages, current_rules)
    
    # Update store
    await store.aput(namespace, key, {"rules": new_rules})
    
    print(f"[LEARNING] Updated Rules: {new_rules}")
    
    return {}

async def generate_node(state: MarketingState, store: BaseStore) -> Dict[str, Any]:
    """
    ç”ŸæˆèŠ‚ç‚¹: åŸºäºŽæ–‡æ¡£ç”Ÿæˆè¥é”€å»ºè®® (Marketing Context)
    æ”¯æŒ Fallback: æ— ç›¸å…³æ–‡æ¡£æ—¶ä½¿ç”¨é€šç”¨å›žç­”
    """
    print("[GENERATE] Creating Answer")

    question = state.get("question")
    documents = state.get('retrieved_docs', '')
    retry_count = state.get("retry_count", 0)

    # Get user rules
    namespace = ("marketing_preferences",)
    key = "user_rules"
    current_rules_item = await store.aget(namespace, key)
    user_rules = current_rules_item.value["rules"] if current_rules_item and "rules" in current_rules_item.value else "*no rules yet*"

    # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å…³æ–‡æ¡£
    has_documents = bool(documents and documents.strip())

    if has_documents:
        # æ­£å¸¸æ¨¡å¼: åŸºäºŽæ–‡æ¡£ç”Ÿæˆ
        system_prompt = """You are an expert AI Marketing Consultant providing actionable, strategic advice.

    USER PREFERENCES:
    {user_rules}

    OUTPUT FORMAT:
    Write a comprehensive, engaging answer (200-300 words) in MARKDOWN format:
    - Use ## headings for key strategies
    - Use **bold** for emphasis
    - Use bullet points for actionable steps
    - Include inline citations like [1], [2] where applicable

    GUIDELINES:
    - Base your advice ONLY on the provided documents, but synthesize them into a coherent strategy.
    - Focus on marketing metrics (ROI, conversion, engagement) rather than just financial data.
    - Be practical and solution-oriented.
    - Use professional marketing terminology.

    CITATIONS:
    At the end, list references in this format:
    **References:**
    1. Source: [Document Name/Snippet]"""

        system_prompt = system_prompt.format(user_rules=user_rules)
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"Retrieved Document: {documents}\n\nUser query: {question}")
        ]
    else:
        # Fallback æ¨¡å¼: æ²¡æœ‰ç›¸å…³æ–‡æ¡£ï¼Œä½¿ç”¨é€šç”¨å›žç­”
        print(f"[GENERATE] Fallback mode - No relevant documents (retry_count: {retry_count})")
        system_prompt = """You are an AI Marketing Consultant.

The user's question doesn't seem to have relevant documents in our marketing knowledge base.

INSTRUCTIONS:
- If it's a general question (like "who are you"), introduce yourself as an AI Marketing teacher/consultant.
- If it's a marketing question we don't have docs for, provide general marketing principles and suggest the user upload relevant materials.
- Be helpful and friendly.
- Keep the response concise (100-150 words).
- Use MARKDOWN format.

USER PREFERENCES:
{user_rules}"""

        system_prompt = system_prompt.format(user_rules=user_rules)
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"User query: {question}")
        ]

    response = await llm.ainvoke(messages)
    generation = response.content

    return {
        'generation': generation,
        'messages': [AIMessage(content=generation)]
    }

def transform_query_node(state: MarketingState) -> Dict[str, Any]:
    """
    æŸ¥è¯¢é‡å†™èŠ‚ç‚¹: å°†å¤æ‚é—®é¢˜æ‹†è§£ä¸ºå…·ä½“çš„è¥é”€æœç´¢æŸ¥è¯¢ (Marketing Context)
    """
    print("[TRANSFORM] Rewriting query")

    question = state.get("question")
    rewritten_queries = state.get('rewritten_queries', [])
    retry_count = state.get("retry_count", 0) + 1  # å¢žåŠ é‡è¯•è®¡æ•°

    llm_structured = llm.with_structured_output(SearchQueries)

    # Adapted Prompt for Marketing
    system_prompt = """You are a marketing research assistant that decomposes complex marketing questions into focused search queries.

    DECOMPOSITION STRATEGY:
    Break down the original query into 1-3 specific, focused queries targeting:
    - Specific marketing channels (e.g., "SEO trends 2024", "Social media benchmarks")
    - Target audience segments
    - Competitor strategies
    - Specific metrics (e.g., "CAC benchmarks", "Retention rates")

    GUIDELINES:
    - Expand marketing acronyms (e.g., "PPC" -> "Pay-per-click")
    - Add marketing context if missing
    - Make each query self-contained and specific
    - Keep queries concise

    EXAMPLES:
    - "How to improve ROI on Facebook Ads?" -> 
    ["Facebook Ads ROI optimization strategies", "Facebook advertising benchmarks 2024"]
    """

    query_context = f"Original Query: {question}"
    if rewritten_queries:
        query_context += f"\n\nThese queries have been already generated. Do not generate same queries again.\n"
        for idx, q in enumerate(rewritten_queries, 1):
            query_context += f"Query {idx}: {q}\n"

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=query_context)
    ]

    response = llm_structured.invoke(messages)
    new_queries = response.search_queries
    
    print(f"[TRANSFORM] New Queries: {new_queries} (retry: {retry_count})")

    return {
        "rewritten_queries": new_queries,
        "retry_count": retry_count  # è¿”å›žæ›´æ–°åŽçš„é‡è¯•è®¡æ•°
    }

def check_answer_quality(state: MarketingState) -> Dict[str, Any]:
    """
    å¹»è§‰æ£€æµ‹ä¸Žè´¨é‡è¯„ä¼°èŠ‚ç‚¹
    """
    print("[CHECK] Checking answer quality")
    
    question = state.get("question")
    documents = state.get('retrieved_docs', '')
    generation = state.get("generation")

    # 1. Hallucination Check
    llm_hallucinations = llm.with_structured_output(GradeHallucinations)
    
    hallucination_prompt = """You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts.
    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts."""

    messages = [
        SystemMessage(content=hallucination_prompt),
        HumanMessage(content=f"Set of facts:\n\n{documents}\n\nLLM Generation: {generation}")
    ]
    
    try:
        res_hallucination = llm_hallucinations.invoke(messages)
        hallucination_grade = res_hallucination.binary_score
    except:
        hallucination_grade = "yes"

    print(f"[CHECK] Hallucination Grade: {hallucination_grade}")

    if hallucination_grade == 'yes':
        # 2. Answer Quality Check
        llm_answer = llm.with_structured_output(GradeAnswer)
        
        answer_prompt = """You are a grader assessing whether an answer addresses / resolves a query.
        Give a binary score 'yes' or 'no'. 'Yes' means that the answer resolves the query."""
        
        messages = [
            SystemMessage(content=answer_prompt),
            HumanMessage(content=f"User Query: {question}\n\n LLM Generation: {generation}")
        ]
        
        try:
            res_answer = llm_answer.invoke(messages)
            answer_grade = res_answer.binary_score
        except:
            answer_grade = "yes"
            
        print(f"[CHECK] Answer Grade: {answer_grade}")
        
        return {
            "hallucination_grade": hallucination_grade,
            "answer_grade": answer_grade
        }
    else:
        return {
            "hallucination_grade": hallucination_grade,
            "answer_grade": "no"
        }

# =============================================================================
# Web Search Node (White-box Reuse)
# å¤ç”¨æ¥æº: menonpg/agentic_search_openai_langgraph, psykick-21/deep-research
# =============================================================================

def web_search_node(state: MarketingState) -> Dict[str, Any]:
    """
    Web Search èŠ‚ç‚¹: æ”¯æŒä¸¤ç§æ¨¡å¼
    1. çº¯ Web æœç´¢: å½“çŸ¥è¯†åº“å®Œå…¨ä¸ç›¸å…³æ—¶
    2. è¡¥å……æ··åˆ: å½“çŸ¥è¯†åº“éƒ¨åˆ†ç›¸å…³æ—¶ï¼Œåˆå¹¶ä¸¤ä¸ªæ¥æº

    å¤ç”¨ç­–ç•¥:
    - ç›´æŽ¥å¤ç”¨ langchain_community.tools.DuckDuckGoSearchResults
    - æ”¯æŒå¯é€‰çš„ Tavily (éœ€è¦ API Key)
    """
    print("[WEB_SEARCH] Initiating web search...")

    question = state.get("question", "")
    rewritten_queries = state.get("rewritten_queries", [])
    kb_docs = state.get("kb_docs", "")  # èŽ·å–å·²æœ‰çš„çŸ¥è¯†åº“æ–‡æ¡£
    current_grade = state.get("grade", "no")

    # è°ƒè¯•ä¿¡æ¯
    print(f"[WEB_SEARCH] Current grade: {current_grade}")
    print(f"[WEB_SEARCH] KB docs available: {bool(kb_docs and kb_docs.strip())}")
    if kb_docs:
        print(f"[WEB_SEARCH] KB docs preview: {kb_docs[:200]}...")

    # ä½¿ç”¨é‡å†™åŽçš„æŸ¥è¯¢æˆ–åŽŸå§‹é—®é¢˜
    search_query = rewritten_queries[-1] if rewritten_queries else question

    # åˆå§‹åŒ–æœç´¢å·¥å…· (White-box Reuse: langchain_community)
    use_tavily = settings.USE_TAVILY and settings.TAVILY_API_KEY

    try:
        if use_tavily:
            from langchain_community.tools.tavily_search import TavilySearchResults
            search_tool = TavilySearchResults(
                max_results=5,
                search_depth="advanced",
                include_answer=True
            )
            print("[WEB_SEARCH] Using Tavily Search API")
        else:
            search_tool = DuckDuckGoSearchResults(
                max_results=5,
                output_format="list"
            )
            print("[WEB_SEARCH] Using DuckDuckGo Search")

        # æ‰§è¡Œæœç´¢
        results = search_tool.invoke(search_query)

        # æ ¼å¼åŒ–æœç´¢ç»“æžœ
        if isinstance(results, list):
            web_docs = []
            for i, r in enumerate(results, 1):
                if isinstance(r, dict):
                    title = r.get("title", "Untitled")
                    snippet = r.get("snippet", r.get("body", r.get("content", "")))
                    link = r.get("link", r.get("url", ""))
                    web_docs.append(f"[Web Source {i}] {title}\n{snippet}\nURL: {link}")
                else:
                    web_docs.append(f"[Web Source {i}] {str(r)}")
            web_results = "\n\n".join(web_docs)
        else:
            web_results = str(results)

        print(f"[WEB_SEARCH] Retrieved {len(results) if isinstance(results, list) else 1} results")

        # å†³å®šæ˜¯æ··åˆæ¨¡å¼è¿˜æ˜¯çº¯ Web æ¨¡å¼
        if current_grade == "partial" and kb_docs:
            # è¡¥å……æ··åˆæ¨¡å¼: åˆå¹¶çŸ¥è¯†åº“å’Œ Web ç»“æžœ
            print("[WEB_SEARCH] Hybrid mode - Merging KB docs with Web results")
            combined_docs = f"""## Knowledge Base Documents (Internal Sources)

{kb_docs}

---

## Web Search Supplement for: {search_query}

{web_results}"""
            source_type = "hybrid"
        else:
            # çº¯ Web æ¨¡å¼
            combined_docs = f"## Web Search Results for: {search_query}\n\n{web_results}"
            source_type = "web_search"

        return {
            "retrieved_docs": combined_docs,
            "web_docs": web_results,
            "source_type": source_type,
            "grade": "yes"  # æœç´¢å®Œæˆï¼Œå¯ä»¥è¿›å…¥ç”Ÿæˆ
        }

    except Exception as e:
        print(f"[WEB_SEARCH] Error: {e}")
        # å¦‚æžœ Web æœç´¢å¤±è´¥ä½†æœ‰çŸ¥è¯†åº“æ–‡æ¡£ï¼Œä»ç„¶ä½¿ç”¨çŸ¥è¯†åº“
        if kb_docs:
            return {
                "retrieved_docs": kb_docs,
                "source_type": "knowledge_base",
                "grade": "yes"
            }
        return {
            "retrieved_docs": f"Web search failed: {str(e)}",
            "source_type": "fallback",
            "grade": "yes"
        }

# =============================================================================
# Routers
# =============================================================================

def check_approval(state: MarketingState) -> str:
    """
    è·¯ç”±: æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ‰¹å‡†ç”Ÿæˆ
    """
    feedback = state.get("user_feedback")
    if feedback == "approved":
        print("[ROUTER] User approved -> Generate")
        return "generate"
    else:
        print("[ROUTER] User rejected -> Transform Query")
        return "transform_query"

def should_generate(state: MarketingState) -> str:
    """
    è·¯ç”±: å†³å®šæ˜¯ç”Ÿæˆå›žç­”ã€é‡å†™æŸ¥è¯¢è¿˜æ˜¯è§¦å‘ Web æœç´¢

    ç­–ç•¥ (CRAG + Web Search Fallback + è¡¥å……æ··åˆ):
    - force_web_search == True -> ç›´æŽ¥è¿›è¡Œ Web æœç´¢
    - grade == 'yes' -> ç›´æŽ¥ç”Ÿæˆ
    - grade == 'partial' -> è¡¥å…… Web æœç´¢ï¼ˆæ··åˆæ¨¡å¼ï¼‰
    - retry_count >= 2 -> è§¦å‘ Web æœç´¢
    - å¦åˆ™ -> é‡å†™æŸ¥è¯¢
    """
    grade = state.get("grade")
    retry_count = state.get("retry_count", 0)
    force_web_search = state.get("force_web_search", False)
    max_retries_before_web = 2  # 2æ¬¡çŸ¥è¯†åº“é‡è¯•åŽè§¦å‘ Web æœç´¢
    max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

    # ç”¨æˆ·æ˜Žç¡®è¯·æ±‚ Web æœç´¢
    if force_web_search:
        print("[ROUTER] User explicitly requested Web Search -> Web Search")
        return "web_search"

    if grade == "yes":
        print("[ROUTER] Documents relevant -> Generate")
        return "generate"
    elif grade == "partial":
        # éƒ¨åˆ†ç›¸å…³ï¼šè§¦å‘è¡¥å…… Web æœç´¢ï¼ˆæ··åˆæ¨¡å¼ï¼‰
        print("[ROUTER] Documents partially relevant -> Supplement with Web Search (Hybrid)")
        return "web_search"
    elif retry_count >= max_retries_before_web and retry_count < max_retries:
        print(f"[ROUTER] KB retries exhausted ({retry_count}) -> Web Search")
        return "web_search"
    elif retry_count >= max_retries:
        print(f"[ROUTER] Max retries ({max_retries}) reached -> Force Generate (Fallback)")
        return "generate"  # è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œå¼ºåˆ¶è¿›å…¥ç”Ÿæˆé˜¶æ®µ
    else:
        print(f"[ROUTER] Documents irrelevant (retry {retry_count + 1}/{max_retries}) -> Transform Query")
        return "transform_query"

def check_hallucination_router(state: MarketingState) -> str:
    """
    è·¯ç”±: å†³å®šæ˜¯ç»“æŸã€é‡å†™æŸ¥è¯¢è¿˜æ˜¯é‡æ–°ç”Ÿæˆ
    æ·»åŠ é‡è¯•é™åˆ¶ï¼Œé˜²æ­¢æ— é™å¾ªçŽ¯
    """
    hallucination_grade = state.get("hallucination_grade")
    answer_grade = state.get("answer_grade")
    retry_count = state.get("retry_count", 0)
    max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

    if hallucination_grade == "yes":
        if answer_grade == "yes":
            print("[ROUTER] Answer is good -> END")
            return "useful"  # Map to learning node in graph
        elif retry_count >= max_retries:
            print(f"[ROUTER] Max retries ({max_retries}) reached -> Force END (Fallback)")
            return "useful"  # è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œå¼ºåˆ¶ç»“æŸ
        else:
            print(f"[ROUTER] Answer not useful (retry {retry_count}/{max_retries}) -> Transform Query")
            return "not useful"
    else:
        if retry_count >= max_retries:
            print(f"[ROUTER] Hallucination detected but max retries reached -> Force END")
            return "useful"  # è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œå¼ºåˆ¶ç»“æŸ
        print("[ROUTER] Hallucination detected -> Not Supported")
        return "not supported"

# AI 新媒体营销运营老师智能体 - 项目复用方案（完整版）

## 项目组合（4个项目）

| 角色 | GitHub 项目 | 复用内容 |
|------|------------|----------|
| **主体** | [laxmimerit/Agentic-RAG-with-LangGraph-and-Ollama](https://github.com/laxmimerit/Agentic-RAG-with-LangGraph-and-Ollama) | 完整CRAG + 幻觉检测 + 文档相关性评估 + FastAPI + LangGraph + ChromaDB |
| **HITL 补充** | [JoshuaC215/agent-service-toolkit](https://github.com/JoshuaC215/agent-service-toolkit) | interrupt_before/after 中断逻辑 |
| **营销逻辑** | [langchain-ai/content-writer](https://github.com/langchain-ai/content-writer) | 营销内容生成 Prompt 和工作流,官方内容 Agent + 用户反馈学习 |
| **前端** | [IBJunior/fullstack-langgraph-nextjs-agent](https://github.com/IBJunior/fullstack-langgraph-nextjs-agent) | Next.js + 历史记录 + 会话管理 + SSE + HITL UI |

---

## 技术栈
- **LLM**: DeepSeek (OpenAI SDK 兼容)
- **RAG**: ChromaDB
- **编排**: LangGraph
- **后端**: FastAPI
- **前端**: Next.js 15

---

## 实施步骤

### Phase 1: 克隆主体项目
```bash
git clone https://github.com/laxmimerit/Agentic-RAG-with-LangGraph-and-Ollama.git
cd Agentic-RAG-with-LangGraph-and-Ollama
pip install -r requirements.txt
pip install langchain-openai
```

### Phase 2: 替换 LLM 为 DeepSeek
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="deepseek-chat",
    openai_api_key="YOUR_KEY",
    openai_api_base="https://api.deepseek.com/v1",
    temperature=0.7
)
```

### Phase 3: 添加营销 Prompt（从 content-writer）
```python
MARKETING_PROMPT = """你是专业的 AI 新媒体营销运营老师。
擅长：营销策略、文案优化、用户增长、品牌定位

知识库: {context}
问题: {question}

请提供专业建议：
"""

def generate_node(state):
    context = "\n\n".join([d.page_content for d in state["documents"]])
    prompt = MARKETING_PROMPT.format(context=context, question=state["question"])
    return {"generation": llm.invoke(prompt).content}
```

### Phase 4: 添加 HITL（从 agent-service-toolkit）
```python
from langgraph.checkpoint.memory import MemorySaver

workflow.add_node("human_review", lambda s: s)
workflow.add_edge("hallucination_check", "human_review")

graph = workflow.compile(
    checkpointer=MemorySaver(),
    interrupt_before=["human_review"]
)
```

### Phase 5: FastAPI 接口
```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

@app.post("/chat")
async def chat(question: str, thread_id: str):
    config = {"configurable": {"thread_id": thread_id}}
    result = await graph.ainvoke({"question": question}, config)
    return {"answer": result["generation"]}

@app.post("/chat/stream")
async def stream(question: str, thread_id: str):
    async def generate():
        config = {"configurable": {"thread_id": thread_id}}
        async for event in graph.astream_events({"question": question}, config, version="v2"):
            if event["event"] == "on_chat_model_stream":
                yield f"data: {event['data']['chunk'].content}\n\n"
        yield "data:
        </parameter>
    return StreamingResponse(generate(), media_type="text/event-stream")

# HITL 审批接口
@app.post("/chat/state")
async def get_state(thread_id: str):
    """获取当前状态（用于检查是否需要审批）"""
    config = {"configurable": {"thread_id": thread_id}}
    state = graph.get_state(config)
    return {"next": state.next, "values": state.values}

@app.post("/chat/approve")
async def approve(thread_id: str, approved: bool):
    """审批并恢复执行"""
    config = {"configurable": {"thread_id": thread_id}}
    if approved:
        result = await graph.ainvoke(None, config)
        return {"answer": result.get("generation"), "approved": True}
    else:
        return {"answer": "已拒绝", "approved": False}
Phase 6: Next.js 前端集成
克隆前端项目：

git clone https://github.com/IBJunior/fullstack-langgraph-nextjs-agent.git frontend
cd frontend
npm install
修改 API 端点配置（src/app/api/agent/stream/route.ts）：

const BACKEND_URL = "http://localhost:8000";

export async function POST(req: Request) {
  const { message, threadId } = await req.json();
  
  // 对接 FastAPI 后端
  const response = await fetch(`${BACKEND_URL}/chat/stream`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ question: message, thread_id: threadId }),
  });
  
  return new Response(response.body, {
    headers: { "Content-Type": "text/event-stream" },
  });
}
关键文件清单
来源项目	文件/模块	用途
Agentic-RAG	graph.py	LangGraph 主工作流定义
Agentic-RAG	nodes/*.py	CRAG 各节点实现（retrieve, grade, generate等）
Agentic-RAG	requirements.txt	Python 依赖列表
agent-service-toolkit	HITL 相关代码	interrupt_before/after 逻辑
content-writer	Prompt 模板	营销内容生成的 Prompt 设计
fullstack-nextjs	src/app/api/agent/	API 路由
fullstack-nextjs	src/components/chat/	聊天 UI 组件
fullstack-nextjs	src/components/tool-approval/	HITL 审批 UI
注意事项
DeepSeek Function Calling: DeepSeek 的 function calling 格式可能与 OpenAI 略有不同，需要测试适配
ChromaDB 持久化: 配置数据目录，如 ./chroma_db
CORS 配置: FastAPI 需要允许前端域名访问
环境变量:

DEEPSEEK_API_KEY=your_key
DEEPSEEK_API_BASE=https://api.deepseek.com/v1
CHROMA_DB_PATH=./chroma_db
LangGraph 版本: 确保 langgraph>=0.2.0，支持 interrupt_before/after
Sources
laxmimerit/Agentic-RAG-with-LangGraph-and-Ollama
JoshuaC215/agent-service-toolkit
langchain-ai/content-writer
IBJunior/fullstack-langgraph-nextjs-agent


---

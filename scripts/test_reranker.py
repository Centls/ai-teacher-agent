#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯• Reranker åŠŸèƒ½

éªŒè¯ï¼š
1. CrossEncoder æ¨¡å‹åŠ è½½
2. CPU/GPU è‡ªåŠ¨æ£€æµ‹
3. é‡æ’åºåŠŸèƒ½
"""
import sys
import os
from pathlib import Path

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == "win32":
    os.environ["PYTHONIOENCODING"] = "utf-8"
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from config.settings import settings, MODELS_DIR


def test_reranker_config():
    """æµ‹è¯•é…ç½®"""
    print("=" * 60)
    print("1. é…ç½®æ£€æŸ¥")
    print("=" * 60)
    print(f"   RERANKER_ENABLED: {settings.RERANKER_ENABLED}")
    print(f"   RERANKER_MODEL: {settings.RERANKER_MODEL}")
    print(f"   RERANKER_MAX_LENGTH: {settings.RERANKER_MAX_LENGTH}")
    print(f"   RERANKER_DEVICE: {settings.RERANKER_DEVICE}")
    print(f"   MODELS_DIR: {MODELS_DIR}")
    print(f"   HF_HOME: {MODELS_DIR / 'huggingface'}")
    print()


def test_device_detection():
    """æµ‹è¯•è®¾å¤‡æ£€æµ‹"""
    print("=" * 60)
    print("2. è®¾å¤‡æ£€æµ‹")
    print("=" * 60)

    import torch
    print(f"   PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"   CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   CUDA è®¾å¤‡: {torch.cuda.get_device_name(0)}")

    mps_available = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()
    print(f"   MPS å¯ç”¨ (Apple): {mps_available}")
    print()


def test_reranker_loading():
    """æµ‹è¯• Reranker åŠ è½½"""
    print("=" * 60)
    print("3. Reranker æ¨¡å‹åŠ è½½")
    print("=" * 60)

    from src.services.rag.pipeline import RAGPipeline, _get_reranker_device

    device = _get_reranker_device()
    print(f"   æ£€æµ‹åˆ°è®¾å¤‡: {device}")

    # åˆ›å»º Pipeline å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼Œä¸ä¼šç«‹å³åŠ è½½ Rerankerï¼‰
    print("   æ­£åœ¨åˆå§‹åŒ– RAGPipeline...")

    # ç›´æ¥æµ‹è¯• CrossEncoder åŠ è½½
    print(f"   æ­£åœ¨åŠ è½½ Reranker: {settings.RERANKER_MODEL}")
    print("   (é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…...)")

    from sentence_transformers import CrossEncoder

    reranker = CrossEncoder(
        settings.RERANKER_MODEL,
        max_length=settings.RERANKER_MAX_LENGTH,
        device=device,
        trust_remote_code=True
    )
    print(f"   âœ… Reranker åŠ è½½æˆåŠŸ!")
    print()

    return reranker


def test_reranking(reranker):
    """æµ‹è¯•é‡æ’åºåŠŸèƒ½"""
    print("=" * 60)
    print("4. é‡æ’åºåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)

    query = "å¦‚ä½•æé«˜è¥é”€æ•ˆæœ"
    documents = [
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºå»æ•£æ­¥ã€‚",
        "è¥é”€ç­–ç•¥éœ€è¦ç»“åˆç›®æ ‡ç”¨æˆ·ç¾¤ä½“çš„ç‰¹ç‚¹æ¥åˆ¶å®šã€‚",
        "Python æ˜¯ä¸€é—¨æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ã€‚",
        "æé«˜è¥é”€æ•ˆæœçš„å…³é”®åœ¨äºç²¾å‡†å®šä½å’Œå†…å®¹ä¼˜åŒ–ã€‚",
        "æœºå™¨å­¦ä¹ åœ¨æ¨èç³»ç»Ÿä¸­æœ‰å¹¿æ³›åº”ç”¨ã€‚",
    ]

    print(f"   æŸ¥è¯¢: {query}")
    print(f"   æ–‡æ¡£æ•°: {len(documents)}")
    print()

    # æ„å»º query-document pairs
    pairs = [[query, doc] for doc in documents]

    # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
    scores = reranker.predict(pairs)

    # æ’åº
    ranked = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)

    print("   æ’åºç»“æœ:")
    for i, (doc, score) in enumerate(ranked, 1):
        print(f"   {i}. [åˆ†æ•°: {score:.4f}] {doc[:50]}...")
    print()

    # éªŒè¯ï¼šè¥é”€ç›¸å…³æ–‡æ¡£åº”è¯¥æ’åœ¨å‰é¢
    top_doc = ranked[0][0]
    assert "è¥é”€" in top_doc, f"é¢„æœŸè¥é”€ç›¸å…³æ–‡æ¡£æ’åœ¨ç¬¬ä¸€ï¼Œå®é™…: {top_doc}"
    print("   âœ… é‡æ’åºåŠŸèƒ½æ­£å¸¸!")
    print()


def main():
    print()
    print("ğŸš€ BGE-Reranker-v2-m3 åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    print()

    # 1. é…ç½®æ£€æŸ¥
    test_reranker_config()

    # 2. è®¾å¤‡æ£€æµ‹
    test_device_detection()

    # 3. æ¨¡å‹åŠ è½½
    reranker = test_reranker_loading()

    # 4. é‡æ’åºæµ‹è¯•
    test_reranking(reranker)

    print("=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    print("=" * 60)


if __name__ == "__main__":
    main()